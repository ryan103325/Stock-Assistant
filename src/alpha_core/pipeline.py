"""
å°è‚¡æ–°èæƒ…ç·’åˆ†æ - Pipeline ä¸»æµç¨‹
"""

import asyncio
import os
from datetime import datetime
from typing import List, Dict

from .config import RSS_FEEDS, BATCH_SIZE, REQUEST_DELAY
from .database import SentimentDB
from .rss_fetcher import fetch_all_feeds
from .llm_client import get_worker_client


class SentimentPipeline:
    def __init__(self):
        self.db = SentimentDB()
        self.llm = get_worker_client()
        self._load_system_prompt()
        self._load_valid_tickers()
    
    def _load_system_prompt(self):
        """è¼‰å…¥ Worker System Prompt"""
        prompt_path = os.path.join(os.path.dirname(__file__), "prompts", "worker_system.txt")
        with open(prompt_path, 'r', encoding='utf-8') as f:
            self.system_prompt = f.read()
    
    def _load_valid_tickers(self):
        """è¼‰å…¥æœ‰æ•ˆè‚¡ç¥¨æ¸…å–® (å¾ history è³‡æ–™å¤¾)"""
        history_dir = os.path.join(os.path.dirname(__file__), "..", "data_core", "history")
        self.valid_tickers = set()
        if os.path.exists(history_dir):
            for f in os.listdir(history_dir):
                if f.endswith('.csv'):
                    ticker = f.replace('.csv', '')
                    # åªä¿ç•™ 4 ä½æ•¸å­—çš„è‚¡ç¥¨ä»£ç¢¼
                    if ticker.isdigit() and len(ticker) == 4:
                        self.valid_tickers.add(ticker)
        print(f"ğŸ“‹ æœ‰æ•ˆè‚¡ç¥¨æ¸…å–®: {len(self.valid_tickers)} æª”")
    
    # ========== FETCH ==========
    
    def fetch(self):
        """Step 1: æŠ“å–æ–°èä¸¦å­˜å…¥è³‡æ–™åº«"""
        print("=" * 50)
        print("ğŸ“¡ Step 1: FETCH - æŠ“å–æ–°è")
        print("=" * 50)
        
        # 1. æŠ“å–æ‰€æœ‰ RSS
        all_news = fetch_all_feeds(RSS_FEEDS)
        
        # 2. å­˜å…¥è³‡æ–™åº« (å»é‡ç”± URL UNIQUE è™•ç†)
        with self.db as db:
            db.create_tables()
            inserted = 0
            for item in all_news:
                result = db.insert_raw_news(
                    url=item['url'],
                    title=item['title'],
                    source=item['source'],
                    publish_time=item['publish_time'],
                    content=item['content']
                )
                if result:
                    inserted += 1
            
            stats = db.get_stats()
        
        print(f"\nğŸ“Š FETCH å®Œæˆ:")
        print(f"   æ–°å¢: {inserted} å‰‡")
        print(f"   ç¸½è¨ˆ: {stats['total_news']} å‰‡")
        print(f"   å¾…åˆ†æ: {stats['pending_news']} å‰‡")
    
    # ========== ANALYZE ==========
    
    async def analyze(self, limit: int = 100):
        """Step 2: AI æƒ…ç·’åˆ†æ"""
        print("=" * 50)
        print("ğŸ¤– Step 2: ANALYZE - AI æƒ…ç·’åˆ†æ")
        print("=" * 50)
        
        with self.db as db:
            db.create_tables()
            pending = db.get_pending_news(limit=limit)
        
        if not pending:
            print("âœ… æ²’æœ‰å¾…åˆ†æçš„æ–°è")
            return
        
        print(f"ğŸ“° æ‰¾åˆ° {len(pending)} å‰‡å¾…åˆ†ææ–°è")
        
        # åˆ†æ‰¹è™•ç†
        pending_list = [dict(row) for row in pending]
        batches = [pending_list[i:i+BATCH_SIZE] for i in range(0, len(pending_list), BATCH_SIZE)]
        
        total_analyzed = 0
        total_sentiments = 0
        
        for batch_idx, batch in enumerate(batches):
            print(f"\nğŸ”„ Processing batch {batch_idx+1}/{len(batches)} ({len(batch)} items)...")
            
            # çµ„åˆ User Prompt
            user_prompt = self._build_user_prompt(batch)
            
            # å‘¼å« LLM
            result = await self.llm.generate(self.system_prompt, user_prompt)
            
            if result:
                # å„²å­˜çµæœ
                with self.db as db:
                    for item in result:
                        # æ‰¾åˆ°å°æ‡‰çš„åŸå§‹æ–°è
                        matching = next((n for n in batch if n['url'] == item.get('url')), None)
                        if matching:
                            news_id = matching['id']
                            
                            # æ›´æ–°æ–°èåˆ†æ
                            db.update_analysis(
                                news_id=news_id,
                                summary=item.get('summary', ''),
                                score=item.get('overall_sentiment_score', 0),
                                label=item.get('overall_sentiment_label', 'Neutral')
                            )
                            total_analyzed += 1
                            
                            # æ’å…¥å€‹è‚¡æƒ…ç·’ (åªä¿ç•™æœ‰æ•ˆè‚¡ç¥¨)
                            for ticker_item in item.get('ticker_sentiment', []):
                                ticker = ticker_item.get('ticker', '')
                                # éæ¿¾ï¼šåªä¿ç•™ history è³‡æ–™å¤¾ä¸­æœ‰çš„è‚¡ç¥¨
                                if ticker not in self.valid_tickers:
                                    continue
                                    
                                db.insert_ticker_sentiment(
                                    news_id=news_id,
                                    ticker=ticker,
                                    relevance=ticker_item.get('relevance_score', 0),
                                    score=ticker_item.get('sentiment_score', 0),
                                    label=ticker_item.get('sentiment_label', 'Neutral')
                                )
                                total_sentiments += 1
            
            # å»¶é²é¿å… Rate Limit
            if batch_idx < len(batches) - 1:
                await asyncio.sleep(REQUEST_DELAY)
        
        print(f"\nğŸ“Š ANALYZE å®Œæˆ:")
        print(f"   åˆ†æ: {total_analyzed} å‰‡æ–°è")
        print(f"   å€‹è‚¡æƒ…ç·’: {total_sentiments} ç­†")
    
    def _build_user_prompt(self, batch: List[Dict]) -> str:
        """å»ºæ§‹ User Prompt"""
        items = []
        for i, news in enumerate(batch):
            items.append(f"""
### News {i+1}
- URL: {news['url']}
- Title: {news['title']}
- Source: {news['source']}
- Content: {news['content'][:2000]}
""")
        
        return "\n".join(items)
    
    # ========== STATS ==========
    
    def stats(self):
        """é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š"""
        with self.db as db:
            db.create_tables()
            stats = db.get_stats()
        
        print("\nğŸ“Š è³‡æ–™åº«çµ±è¨ˆ:")
        print(f"   æ–°èç¸½æ•¸: {stats['total_news']}")
        print(f"   å·²åˆ†æ: {stats['analyzed_news']}")
        print(f"   å¾…åˆ†æ: {stats['pending_news']}")
        print(f"   å€‹è‚¡æƒ…ç·’: {stats['total_sentiments']}")
        print(f"   åçœç´€éŒ„: {stats['total_reflections']}")


# ä¾¿æ·å‡½æ•¸
def run_fetch():
    pipeline = SentimentPipeline()
    pipeline.fetch()

async def run_analyze(limit: int = 100):
    pipeline = SentimentPipeline()
    await pipeline.analyze(limit)

def run_stats():
    pipeline = SentimentPipeline()
    pipeline.stats()
