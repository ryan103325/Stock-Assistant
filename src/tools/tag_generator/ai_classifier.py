"""
AI è¼”åŠ©æ¨™ç±¤åˆ†é¡æ¨¡çµ„
ä½¿ç”¨ OpenAI API é€²è¡Œæ¨™ç±¤åˆ†é¡
"""

import os
import json
import requests
from dotenv import load_dotenv

load_dotenv()

# API è¨­å®š
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # é è¨­ç”¨ä¾¿å®œçš„æ¨¡å‹

# å¯ç”¨çš„æ—ç¾¤é¡åˆ¥
AVAILABLE_GROUPS = [
    "AI", "è¨˜æ†¶é«”", "è¢«å‹•å…ƒä»¶", "PCB", "ICè¨­è¨ˆ", "ICä»£å·¥", "å°æ¸¬",
    "åŠå°é«”è¨­å‚™", "å…‰é€šè¨Š", "é›»å‹•è»Š", "ç¶²é€š", "é¢æ¿", "èˆªé‹", "é‡‘è",
    "è˜‹æœä¾›æ‡‰éˆ", "é›»æºä¾›æ‡‰å™¨", "é€£æ¥å™¨", "æ•£ç†±", "ä¼ºæœå™¨",
    "é£Ÿå“", "æ°´æ³¥", "å¡‘è† ", "ç´¡ç¹”", "é‹¼éµ", "å»ºæ", "æ©Ÿæ¢°",
    "ç‡Ÿå»º", "åŒ–å­¸", "ç”ŸæŠ€é†«ç™‚", "é›»å­é€šè·¯", "é‹å‹•ä¼‘é–’",
    "é›»ä¿¡æœå‹™", "ç™¾è²¨é›¶å”®", "è§€å…‰æ—…éŠ", "é›»æ©Ÿé›»çºœ", "æ©¡è† è¼ªèƒ", "é€ ç´™"
]


def _call_openai(prompt: str) -> str:
    """å‘¼å« OpenAI API"""
    if not OPENAI_API_KEY:
        raise Exception("æœªè¨­å®š OPENAI_API_KEY")
    
    response = requests.post(
        "https://api.openai.com/v1/chat/completions",
        headers={
            "Authorization": f"Bearer {OPENAI_API_KEY}",
            "Content-Type": "application/json"
        },
        json={
            "model": OPENAI_MODEL,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.1,
            "max_tokens": 50
        },
        timeout=30
    )
    
    if response.status_code == 200:
        result = response.json()
        return result['choices'][0]['message']['content'].strip()
    else:
        raise Exception(f"API éŒ¯èª¤ ({response.status_code}): {response.text[:100]}")


def classify_tag_with_ai(tag: str, max_retries: int = 2) -> str:
    """
    ä½¿ç”¨ OpenAI API è‡ªå‹•åˆ†é¡æ¨™ç±¤
    
    Args:
        tag: è¦åˆ†é¡çš„æ¨™ç±¤åç¨±
        max_retries: æœ€å¤§é‡è©¦æ¬¡æ•¸
        
    Returns:
        åˆ†é¡å¾Œçš„æ—ç¾¤åç¨±
    """
    prompt = f"""ä½ æ˜¯å°è‚¡ç”¢æ¥­åˆ†é¡å°ˆå®¶ã€‚è«‹å°‡ä»¥ä¸‹æ¨™ç±¤åˆ†é¡åˆ°æœ€é©åˆçš„æ—ç¾¤ã€‚

æ¨™ç±¤ï¼š{tag}

å¯é¸æ—ç¾¤ï¼š{', '.join(AVAILABLE_GROUPS)}

è¦å‰‡ï¼š
1. åªå›å‚³æ—ç¾¤åç¨±ï¼Œä¸è¦å…¶ä»–æ–‡å­—
2. å¦‚æœæ˜¯ç§‘æŠ€ç›¸é—œä½†ç„¡æ³•ç²¾ç¢ºæ­¸é¡ï¼Œé¸æ“‡æœ€æ¥è¿‘çš„
3. å¦‚æœæ˜¯å‚³çµ±ç”¢æ¥­ä½†ç„¡æ³•ç²¾ç¢ºæ­¸é¡ï¼Œé¸æ“‡æœ€æ¥è¿‘çš„
4. åªèƒ½é¸æ“‡ä¸Šé¢åˆ—å‡ºçš„æ—ç¾¤åç¨±

å›ç­”ï¼š"""

    for attempt in range(max_retries):
        try:
            answer = _call_openai(prompt)
            
            # é©—è­‰å›ç­”æ˜¯å¦åœ¨å¯é¸æ—ç¾¤ä¸­
            if answer in AVAILABLE_GROUPS:
                return answer
            
            # å˜—è©¦æ¨¡ç³ŠåŒ¹é…
            for group in AVAILABLE_GROUPS:
                if group in answer or answer in group:
                    return group
            
            print(f"âš ï¸ AI å›å‚³éé æœŸçµæœ: {answer}ï¼Œä½¿ç”¨é è¨­åˆ†é¡")
                
        except requests.exceptions.ConnectionError:
            print(f"âš ï¸ ç„¡æ³•é€£æ¥ OpenAI APIï¼Œè«‹æª¢æŸ¥ç¶²è·¯")
            break
        except Exception as e:
            print(f"âš ï¸ AI åˆ†é¡éŒ¯èª¤: {e}")
    
    return "å‚³ç”¢å…¶ä»–"  # é è¨­ fallback


def classify_tags_batch(tags: list, use_cache: bool = True) -> dict:
    """
    æ‰¹æ¬¡åˆ†é¡å¤šå€‹æ¨™ç±¤
    
    Args:
        tags: æ¨™ç±¤åˆ—è¡¨
        use_cache: æ˜¯å¦ä½¿ç”¨å¿«å–é¿å…é‡è¤‡å‘¼å«
        
    Returns:
        dict: {æ¨™ç±¤: æ—ç¾¤}
    """
    cache_file = os.path.join(os.path.dirname(__file__), "ai_tag_cache.json")
    
    # è¼‰å…¥å¿«å–
    cache = {}
    if use_cache and os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cache = json.load(f)
        except:
            pass
    
    results = {}
    new_classifications = 0
    
    for tag in tags:
        if tag in cache:
            results[tag] = cache[tag]
        else:
            print(f"ğŸ¤– AI åˆ†é¡: {tag}...", end=" ")
            group = classify_tag_with_ai(tag)
            results[tag] = group
            cache[tag] = group
            new_classifications += 1
            print(f"â†’ {group}")
    
    # å„²å­˜å¿«å–
    if new_classifications > 0 and use_cache:
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache, f, ensure_ascii=False, indent=2)
            print(f"âœ… å·²å„²å­˜ {new_classifications} ç­†æ–°åˆ†é¡åˆ°å¿«å–")
            
            # ç”¢ç”Ÿç¨‹å¼ç¢¼ç‰‡æ®µä¾›æ‰‹å‹•æ•´åˆåˆ° GROUP_MAPPING
            _generate_code_snippet(cache)
        except Exception as e:
            print(f"âš ï¸ å¿«å–å„²å­˜å¤±æ•—: {e}")
    
    return results


def _generate_code_snippet(cache: dict):
    """ç”¢ç”Ÿå¯è²¼åˆ° GROUP_MAPPING çš„ç¨‹å¼ç¢¼ç‰‡æ®µ"""
    snippet_file = os.path.join(os.path.dirname(__file__), "ai_learned_tags.py")
    
    # æŒ‰æ—ç¾¤åˆ†çµ„
    group_tags = {}
    for tag, group in cache.items():
        if group not in group_tags:
            group_tags[group] = []
        group_tags[group].append(tag)
    
    # ç”¢ç”Ÿç¨‹å¼ç¢¼
    lines = [
        '"""',
        'AI å­¸ç¿’åˆ°çš„æ¨™ç±¤åˆ†é¡',
        'å¯æ‰‹å‹•æ•´åˆåˆ° GROUP_MAPPING ä¸­çš„ AUTO_MATCH_KEYWORDS',
        f'ç”¢ç”Ÿæ™‚é–“: {__import__("datetime").datetime.now().strftime("%Y-%m-%d %H:%M")}',
        f'ç¸½è¨ˆ: {len(cache)} å€‹æ¨™ç±¤',
        '"""',
        '',
        'AI_LEARNED_TAGS = {'
    ]
    
    for group, tags in sorted(group_tags.items()):
        tags_str = ', '.join([f'"{t}"' for t in sorted(tags)])
        lines.append(f'    "{group}": [{tags_str}],')
    
    lines.append('}')
    
    try:
        with open(snippet_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        print(f"ğŸ“ å·²ç”¢ç”Ÿç¨‹å¼ç¢¼ç‰‡æ®µ: ai_learned_tags.py")
    except:
        pass


def get_ai_learned_tags() -> dict:
    """å–å¾— AI å­¸ç¿’åˆ°çš„æ¨™ç±¤å°ç…§è¡¨ï¼ˆå¾å¿«å–è¼‰å…¥ï¼‰"""
    cache_file = os.path.join(os.path.dirname(__file__), "ai_tag_cache.json")
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {}


def test_connection():
    """æ¸¬è©¦ OpenAI API é€£ç·š"""
    print(f"ğŸ”Œ æ¸¬è©¦ OpenAI API é€£ç·š...")
    print(f"   æ¨¡å‹: {OPENAI_MODEL}")
    
    if not OPENAI_API_KEY:
        print("âŒ æœªè¨­å®š OPENAI_API_KEY")
        return False
    
    try:
        answer = _call_openai("å›è¦† OK")
        print(f"âœ… OpenAI API é€£ç·šæˆåŠŸ")
        return True
            
    except requests.exceptions.ConnectionError:
        print(f"âŒ ç„¡æ³•é€£æ¥ OpenAI APIï¼Œè«‹æª¢æŸ¥ç¶²è·¯")
        return False
    except Exception as e:
        print(f"âŒ é€£ç·šéŒ¯èª¤: {e}")
        return False


if __name__ == "__main__":
    print(f"ğŸ“¡ ä½¿ç”¨ OpenAI API")
    print(f"   OPENAI_API_KEY: {'å·²è¨­å®š' if OPENAI_API_KEY else 'æœªè¨­å®š'}")
    print(f"   æ¨¡å‹: {OPENAI_MODEL}")
    print()
    
    if test_connection():
        # æ¸¬è©¦åˆ†é¡
        test_tags = ["ç„¡äººæ©Ÿ", "å…ƒå®‡å®™", "é«˜çˆ¾å¤«çƒ", "ç¢³æ¬Š", "3Dåˆ—å°"]
        print(f"\nğŸ¤– æ¸¬è©¦ AI åˆ†é¡...")
        results = classify_tags_batch(test_tags)
        print(f"\nğŸ“Š åˆ†é¡çµæœ:")
        for tag, group in results.items():
            print(f"   {tag} â†’ {group}")
