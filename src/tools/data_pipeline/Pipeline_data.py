# === å…¨è‡ªå‹•å°è‚¡è³‡æ–™åº«ï¼šåš´æ ¼äº¤æ˜“æ—¥åˆ¤æ–·ç‰ˆ (éäº¤æ˜“æ—¥/è³‡æ–™æœªå‡º ç›´æ¥é—œé–‰) ===

import os
import sys
import time
import requests
import pandas as pd
from datetime import datetime, timedelta
from io import StringIO
from dotenv import load_dotenv
load_dotenv()

# ================= è¨­å®šå€ =================
# â˜…â˜…â˜… ä½ çš„ FinMind Token (å¤šçµ„è¼ªæ›¿) â˜…â˜…â˜…
# â˜…â˜…â˜… ä½ çš„ FinMind Token (å¤šçµ„è¼ªæ›¿) â˜…â˜…â˜…
API_KEYS = [
    os.getenv("FINMIND_TOKEN", "")
]

# è³‡æ–™åº«è·¯å¾‘
# è³‡æ–™åº«è·¯å¾‘
SRC_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DATA_FOLDER = os.path.join(SRC_ROOT, "data_core", "history")
META_FOLDER = os.path.join(SRC_ROOT, "data_core", "market_meta")

# ä¸‹è¼‰å¤©æ•¸
HISTORY_DAYS = 2000 

# ================= æ ¸å¿ƒå·¥å…·å‡½æ•¸ =================

def ensure_folder_exists():
    if not os.path.exists(DATA_FOLDER):
        os.makedirs(DATA_FOLDER)
    if not os.path.exists(META_FOLDER):
        os.makedirs(META_FOLDER)
    print(f"ğŸ“ è³‡æ–™åº«: {DATA_FOLDER}")
    print(f"ğŸ“ Metadata: {META_FOLDER}")

def safe_request(url, parameter):
    """ å…·å‚™é‡è©¦æ©Ÿåˆ¶çš„è«‹æ±‚ (æŒ‡æ•¸é€€é¿) """
    retry_count = 0
    wait_time = 30 # åˆå§‹ç­‰å¾…
    
    while retry_count < 8: # å¢åŠ é‡è©¦æ¬¡æ•¸
        try:
            resp = requests.get(url, params=parameter, timeout=20)
            if resp.status_code == 200:
                return resp.json()
            elif resp.status_code == 402 or resp.status_code == 429:
                print(f"âš ï¸ è§¸ç™¼é™åˆ¶ ({resp.status_code})ï¼Œç¬¬ {retry_count+1} æ¬¡é‡è©¦ï¼Œä¼‘æ¯ {wait_time} ç§’...")
                time.sleep(wait_time)
                
                # æŒ‡æ•¸é€€é¿: 30 -> 60 -> 120 -> 240
                wait_time *= 2
                retry_count += 1
            else:
                time.sleep(3)
                retry_count += 1
        except:
            time.sleep(3)
            retry_count += 1
    return None

def check_if_today_is_trading_day():
    """
    â˜… é—œéµåˆ¤æ–·ï¼šæª¢æŸ¥ã€Œä»Šå¤©ã€æ˜¯å¦æœ‰äº¤æ˜“è³‡æ–™
    é‚è¼¯ï¼šç›´æ¥å• FinMind æ‹¿ã€Œä»Šå¤©ã€çš„å¤§ç›¤è³‡æ–™ã€‚
    - å¦‚æœæ‹¿å¾—åˆ° -> ä»£è¡¨ä»Šå¤©æ˜¯äº¤æ˜“æ—¥ä¸”è³‡æ–™å·²æ›´æ–° -> å…è¨±åŸ·è¡Œã€‚
    - å¦‚æœæ‹¿ä¸åˆ° -> ä»£è¡¨ä»Šå¤©æ˜¯å‡æ—¥ï¼Œæˆ–é‚„æ²’æ”¶ç›¤ -> ç¦æ­¢åŸ·è¡Œã€‚
    """
    today_str = datetime.now().strftime('%Y-%m-%d')
    print(f"ğŸ“… ç³»çµ±æ—¥æœŸï¼š{today_str}")
    print("ğŸ” æ­£åœ¨æª¢æŸ¥ä»Šæ—¥æ˜¯å¦ç‚ºã€Œæœ‰æ•ˆäº¤æ˜“æ—¥ã€ä¸”ã€Œè³‡æ–™å·²ç”¢å‡ºã€...")
    
    url = "https://api.finmindtrade.com/api/v4/data"
    parameter = {
        "dataset": "TaiwanStockPrice",
        "data_id": "TAIEX",
        "start_date": today_str, # åªæŠ“ä»Šå¤©
        "token": API_KEYS[0] # ä½¿ç”¨ç¬¬ä¸€çµ„ Key æª¢æŸ¥å³å¯
    }
    
    data = safe_request(url, parameter)
    
    # åˆ¤æ–·å›å‚³å…§å®¹
    if data and "data" in data and len(data["data"]) > 0:
        # é›™é‡ç¢ºèªï¼šå›å‚³çš„æ—¥æœŸå¿…é ˆçœŸçš„æ˜¯ä»Šå¤©
        market_date = data["data"][-1]["date"]
        if market_date == today_str:
            print(f"âœ… ç¢ºèªæˆåŠŸï¼ä»Šæ—¥ ({today_str}) æ˜¯äº¤æ˜“æ—¥ï¼Œä¸”è³‡æ–™å·²æ›´æ–°ã€‚")
            return True
    
    print(f"ğŸ’¤ æª¢æŸ¥çµæœï¼šä»Šæ—¥ ({today_str}) ç„¡äº¤æ˜“è³‡æ–™ã€‚")
    print("   åŸå› å¯èƒ½æ˜¯ï¼š1. é€±æœ«/å‡æ—¥  2. å°šæœªæ”¶ç›¤(è³‡æ–™æœªç”¢å‡º)")
    print("â›” ç¨‹å¼å°‡è‡ªå‹•åœæ­¢ï¼Œä¸åŸ·è¡Œä¸‹è¼‰ã€‚")
    return False

# ================= ç¬¬ä¸€éƒ¨åˆ†ï¼šçˆ¬èŸ²æŠ“æ¸…å–® (å…Token) =================

def get_stock_list_universal():
    """ æš´åŠ›æƒæ HiStock ç¶²é ï¼ŒæŠ“å–æ™®é€šè‚¡æ¸…å–® (æ’é™¤ä¸‹å¸‚/åœç‰Œè‚¡ç¥¨) """
    print("\nğŸ“¡ æ­£åœ¨é€£æ¥ HiStock æŠ“å–æœ€æ–°è‚¡ç¥¨æ¸…å–®...")
    # ä½¿ç”¨åŒ…å«é–‹é«˜ä½æ”¶æ¬„ä½çš„é é¢
    url = "https://histock.tw/stock/rank.aspx?m=2&d=1&p=all"
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        
        response = requests.get(url, headers=headers)
        response.encoding = 'utf-8'
        
        if response.status_code != 200:
            print(f"âŒ é€£ç·šå¤±æ•—: {response.status_code}")
            return []

        html_content = StringIO(response.text)
        dfs = pd.read_html(html_content)
        
        target_df = None
        for df in dfs:
            cols = [str(c) for c in df.columns]
            condition_a = any("ä»£è™Ÿ" in c for c in cols) and any("åç¨±" in c for c in cols)
            
            if not condition_a and len(df) > 0:
                row0 = [str(v) for v in df.iloc[0].values]
                if any("ä»£è™Ÿ" in r for r in row0):
                    df.columns = df.iloc[0]
                    df = df[1:]
                    condition_a = True
            
            if condition_a:
                target_df = df
                break
        
        if target_df is None:
            return []

        # æ¨™æº–åŒ–æ¬„ä½åç¨±
        clean_cols = []
        for c in target_df.columns:
            c_str = str(c)
            if "ä»£è™Ÿ" in c_str: clean_cols.append("ä»£è™Ÿ")
            elif "åç¨±" in c_str: clean_cols.append("åç¨±")
            elif "åƒ¹æ ¼" in c_str: clean_cols.append("æ”¶ç›¤")
            elif "æˆäº¤å€¼" in c_str or "æˆäº¤é¡" in c_str: clean_cols.append("æˆäº¤å€¼")
            elif "å‘¨æ¼²è·Œ" in c_str or "é€±æ¼²è·Œ" in c_str: clean_cols.append("é€±æ¼²è·Œ")
            elif "é–‹ç›¤" in c_str: clean_cols.append("é–‹ç›¤")
            elif "æœ€é«˜" in c_str: clean_cols.append("æœ€é«˜")
            elif "æœ€ä½" in c_str: clean_cols.append("æœ€ä½")
            else: clean_cols.append(c_str)
        target_df.columns = clean_cols

        raw_codes = target_df['ä»£è™Ÿ'].astype(str).tolist()
        valid_list = []
        filtered_count = 0
        suspicious_codes = []  # æŒ¯å¹…=0 ä¸”æˆäº¤å€¼=0 çš„å¯ç–‘è‚¡ç¥¨
        
        for idx, code in enumerate(raw_codes):
            code = code.strip()
            # åŸºæœ¬æ ¼å¼æª¢æŸ¥ï¼š4ä½æ•¸å­—ã€ä¸ä»¥0é–‹é ­
            if len(code) == 4 and not code.startswith('0') and code.isdigit():
                try:
                    row = target_df.iloc[idx]
                    
                    # éæ¿¾ DR è‚¡å’Œç”²ç‰¹è‚¡ (åç¨±æ¬„ä½)
                    stock_name = ""
                    if "åç¨±" in target_df.columns:
                        stock_name = str(row["åç¨±"])
                    if "DR" in stock_name or "ç”²ç‰¹" in stock_name:
                        filtered_count += 1
                        continue
                    
                    # å–å¾—æˆäº¤å€¼
                    trade_val = 0
                    if "æˆäº¤å€¼" in target_df.columns:
                        val_str = str(row["æˆäº¤å€¼"]).replace(",", "").replace("-", "0")
                        try:
                            trade_val = float(val_str) if val_str else 0
                        except:
                            trade_val = 0
                    
                    # å–å¾—æŒ¯å¹…
                    amplitude = 0
                    if "æŒ¯å¹…" in target_df.columns:
                        amp_str = str(row["æŒ¯å¹…"]).replace("%", "").replace(",", "").replace("-", "0")
                        try:
                            amplitude = float(amp_str) if amp_str else 0
                        except:
                            amplitude = 0
                    
                    # æŒ¯å¹…=0 ä¸” æˆäº¤å€¼=0 â†’ éœ€è¦ç”¨ FinMind é©—è­‰
                    if trade_val == 0 and amplitude == 0:
                        suspicious_codes.append(code)
                    else:
                        valid_list.append(code)
                except:
                    valid_list.append(code)
        
        # ä½¿ç”¨ FinMind é©—è­‰å¯ç–‘è‚¡ç¥¨
        if suspicious_codes:
            print(f"ğŸ” ç™¼ç¾ {len(suspicious_codes)} æª”å¯ç–‘è‚¡ç¥¨ï¼Œæ­£åœ¨ç”¨ FinMind é©—è­‰...")
            token = os.getenv("FINMIND_TOKEN", "")
            today = datetime.now()
            start_date = (today - timedelta(days=30)).strftime('%Y-%m-%d')
            
            for code in suspicious_codes:
                try:
                    params = {
                        "dataset": "TaiwanStockPrice",
                        "data_id": code,
                        "start_date": start_date,
                        "token": token
                    }
                    resp = requests.get("https://api.finmindtrade.com/api/v4/data", params=params, timeout=10)
                    
                    if resp.status_code == 200:
                        data = resp.json().get('data', [])
                        if data:
                            # å–å¾—æœ€å¾Œäº¤æ˜“æ—¥
                            last_trade_date = data[-1]['date']
                            last_dt = datetime.strptime(last_trade_date, '%Y-%m-%d')
                            days_since = (today - last_dt).days
                            
                            if days_since <= 10:
                                # æœ€è¿‘æœ‰äº¤æ˜“ï¼Œä¿ç•™
                                valid_list.append(code)
                            else:
                                # è¶…é 10 å¤©æ²’äº¤æ˜“ï¼Œè¦–ç‚ºä¸‹å¸‚
                                filtered_count += 1
                        else:
                            # FinMind ç„¡è³‡æ–™ï¼Œè¦–ç‚ºä¸‹å¸‚
                            filtered_count += 1
                    else:
                        # API éŒ¯èª¤ï¼Œä¿å®ˆèµ·è¦‹ä¿ç•™
                        valid_list.append(code)
                    
                    time.sleep(0.5)  # é™é€Ÿ
                except:
                    valid_list.append(code)
            
            print(f"   âœ… é©—è­‰å®Œæˆ")
        
        valid_list = sorted(list(set(valid_list)))
        print(f"âœ… æˆåŠŸå–å¾—æ¸…å–®ï¼å…± {len(valid_list)} æª”æ™®é€šè‚¡ (å·²éæ¿¾ {filtered_count} æª”)")
        return valid_list

    except Exception as e:
        print(f"âŒ çˆ¬èŸ²ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []


# ================= ç¬¬äºŒéƒ¨åˆ†ï¼šFinMind ä¸‹è¼‰å™¨ =================

# ================= ç¬¬äºŒéƒ¨åˆ†ï¼šFinMind ä¸‹è¼‰å™¨ (å¤šåŸ·è¡Œç·’ä¸¦è¡Œç‰ˆ) =================

def update_stock_single(stock_id, token):
    """ å–®ä¸€è‚¡ç¥¨æ›´æ–° (è¼”åŠ©å‡½å¼) """
    file_path = os.path.join(DATA_FOLDER, f"{stock_id}.csv")
    today_str = datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.now() - timedelta(days=HISTORY_DAYS)).strftime('%Y-%m-%d')
    query_start_date = start_date

    # 1. æª¢æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
    if os.path.exists(file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                if len(lines) > 1:
                    last_line = lines[-1].strip()
                    last_date = last_line.split(',')[0]
                    if last_date == today_str: return False # å·²æ˜¯æœ€æ–°
                    if len(last_date) == 10: query_start_date = last_date
        except: pass

    # 2. ä¸‹è¼‰è³‡æ–™
    url = "https://api.finmindtrade.com/api/v4/data"
    parameter = {
        "dataset": "TaiwanStockPrice",
        "data_id": stock_id,
        "start_date": query_start_date,
        "token": token
    }
    
    data = safe_request(url, parameter)
    if data and "data" in data and len(data["data"]) > 0:
        df_new = pd.DataFrame(data["data"])
        df_new = df_new[['date', 'open', 'max', 'min', 'close', 'Trading_Volume']]
        df_new.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
        
        # Calculate Amount immediately
        df_new['Amount'] = df_new['Close'] * df_new['Volume']
        
        # Merge
        if os.path.exists(file_path):
            try:
                df_old = pd.read_csv(file_path)
                df_final = pd.concat([df_old, df_new]).drop_duplicates(subset=['Date'], keep='last')
            except: df_final = df_new
        else:
            df_final = df_new
            
        df_final.to_csv(file_path, index=False, float_format='%.2f')
        return True
    return False

def orchestrate_update(missing_stocks):
    """ 
    å–®åŸ·è¡Œç·’ + Token è¼ªæ›¿ä¸‹è¼‰å™¨ 
    (è§£æ±º 402 Rate Limit å•é¡Œ) 
    """
    total = len(missing_stocks)
    num_keys = len(API_KEYS)
    print(f"\nğŸš€ å•Ÿå‹• FinMind å®‰å…¨è£œæ¼æ©Ÿåˆ¶")
    print(f"ğŸ”¥ å¾…è£œè‚¡ç¥¨: {total} æª” | å¯ç”¨ Token: {num_keys} çµ„")
    print(f"âš¡ ç­–ç•¥: å–®åŸ·è¡Œç·’è¼ªæ›¿ Token (Round-Robin) + å®‰å…¨é–“éš”")

    updated_count = 0
    
    for i, stock_id in enumerate(missing_stocks):
        # è¼ªæ›¿ä½¿ç”¨ Token
        token = API_KEYS[i % num_keys]
        
        # é¡¯ç¤ºé€²åº¦
        print(f"[{i+1}/{total}] æª¢æŸ¥ {stock_id} (Token: ...{token[-4:]})...", end="\r")
        
        try:
            is_updated = update_stock_single(stock_id, token)
            if is_updated:
                updated_count += 1
                sys.stdout.write(f"[{i+1}/{total}] {stock_id} âœ… æ›´æ–°æˆåŠŸ      \n")
                # æˆåŠŸå¾Œä¼‘æ¯ä¹…ä¸€é» (2ç§’)
                time.sleep(2.0)
            else:
                # æ²’è³‡æ–™æ›´æ–°ï¼Œç¨å¾®ä¼‘æ¯å³å¯ (1ç§’)
                time.sleep(1.0)
                
        except Exception as e:
            print(f"âŒ {stock_id} å¤±æ•—: {e}")
            time.sleep(1.0)
            
    print(f"\nğŸ‰ è£œæ¼å®Œæˆï¼å…±æ›´æ–° {updated_count} æª”ã€‚")

# ================= ä¸»ç¨‹å¼ =================
# ================= ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®˜æ–¹é›™åˆ€æµä¸‹è¼‰å™¨ (TWSE + TPEx) =================

def update_daily_official(valid_whitelist=None, force=False):
    """
    ä½¿ç”¨å®˜æ–¹ä¾†æºæŠ“å–ã€Œç•¶æ—¥ã€æ‰€æœ‰è‚¡ç¥¨è¡Œæƒ…
    1. TWSE (OpenAPI) -> ä¸Šå¸‚
    2. TPEx (Web JSON) -> ä¸Šæ«ƒ
    
    å„ªé»ï¼šåªéœ€ 2 æ¬¡è«‹æ±‚å³å¯æ›´æ–°å…¨å¸‚å ´ï¼Œé¿é–‹ FinMind IP é™åˆ¶ã€‚
    """
    print("\nğŸš€ å•Ÿå‹•ã€Œå®˜æ–¹é›™åˆ€æµã€æ›´æ–°æ¨¡å¼ (TWSE + TPEx)")
    
    today_ad = datetime.now().strftime('%Y-%m-%d') # 2024-12-24
    
    # --- 1. æŠ“å– TWSE ä¸Šå¸‚è³‡æ–™ ---
    print("ğŸ“¡ 1. é€£ç·šè‡³è­‰äº¤æ‰€ (TWSE)...")
    twse_data = []
    try:
        url_twse = "https://openapi.twse.com.tw/v1/exchangeReport/STOCK_DAY_ALL"
        requests.packages.urllib3.disable_warnings()
        r = requests.get(url_twse, verify=False, timeout=30)
        if r.status_code == 200:
            twse_data = r.json()
            print(f"   âœ… å–å¾—ä¸Šå¸‚è³‡æ–™: {len(twse_data)} ç­†")
        else:
            print(f"   âŒ TWSE ä¸‹è¼‰å¤±æ•—: {r.status_code}")
    except Exception as e:
        print(f"   âŒ TWSE é€£ç·šéŒ¯èª¤ (Skip): {e}")

    # --- 2. æŠ“å– TPEx ä¸Šæ«ƒè³‡æ–™ (Official Open API) ---
    print("ğŸ“¡ 2. é€£ç·šè‡³æ«ƒè²·ä¸­å¿ƒ (TPEx Open API)...")
    tpex_data = []
    try:
        # User æŒ‡å®šçš„ TPEx Open API å…¥å£: https://www.tpex.org.tw/openapi/
        # å¯¦éš›è³‡æ–™ Endpoint: tpex_mainboard_daily_close_quotes
        url_tpex = "https://www.tpex.org.tw/openapi/v1/tpex_mainboard_daily_close_quotes"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)',
            'Accept': 'application/json'
        }
        # é—œé–‰ SSL é©—è­‰ä»¥é˜²æ†‘è­‰å•é¡Œ
        r = requests.get(url_tpex, headers=headers, verify=False, timeout=20)
        
        if r.status_code == 200:
            tpex_data = r.json()
            print(f"   âœ… å–å¾—ä¸Šæ«ƒè³‡æ–™: {len(tpex_data)} ç­† (ä¾†æº: TPEx Open API)")
        else:
            print(f"   âŒ TPEx ä¸‹è¼‰å¤±æ•—: {r.status_code}")
    except Exception as e:
        print(f"   âŒ TPEx é€£ç·šéŒ¯èª¤ (Skip): {e}")

    # --- 3. æ•´åˆèˆ‡å¯«å…¥ ---
    # --- 3. æ•´åˆèˆ‡å¯«å…¥ ---
    if not twse_data and not tpex_data:
        print("âŒ å®˜æ–¹ä¾†æºçš†ç„¡è³‡æ–™ï¼Œåˆ‡æ›å› FinMind æ¨¡å¼...")
        return False
        
    # [Patch] æª¢æŸ¥è³‡æ–™æ—¥æœŸæ˜¯å¦ç‚ºä»Šæ—¥
    # éš¨æ©ŸæŠ½æ¨£æª¢æŸ¥ TWSE ç¬¬ä¸€ç­†æœ‰æ•ˆè³‡æ–™
    sample_date = ""
    if twse_data:
        try:
            d_str = twse_data[0]['Date'] # 1131226
            y = int(d_str[:3]) + 1911
            m = d_str[3:5]
            d = d_str[5:7]
            sample_date = f"{y}-{m}-{d}"
        except: pass
        
    if sample_date and sample_date != today_ad:
        if force:
            print(f"âš ï¸ [Force Mode] å®˜æ–¹è³‡æ–™æ—¥æœŸ ({sample_date}) èˆ‡ä»Šæ—¥ä¸ç¬¦ï¼Œä½†å¼·åˆ¶æ¡ç´ï¼")
        else:
            print(f"âš ï¸ å®˜æ–¹è³‡æ–™éæœŸï¼(TWSE: {sample_date}, Today: {today_ad})")
            print("ğŸ”„ æ”¾æ£„å®˜æ–¹è³‡æ–™ï¼Œå¼·åˆ¶åˆ‡æ›å› FinMind è£œæ¼æ¨¡å¼ (è¼ƒæ…¢ä½†æº–ç¢º)...")
            return False

    print("ğŸ’¾ æ­£åœ¨æ•´åˆä¸¦å¯«å…¥æœ¬åœ°è³‡æ–™åº«...")
    updated_count = 0
    
    # å»ºç«‹è¦æ›´æ–°çš„è³‡æ–™è¡¨ (Code -> DataDict)
    # æ ¼å¼çµ±ä¸€è½‰ç‚º: Date, Open, High, Low, Close, Volume
    
    # è™•ç† TWSE
    # API: Code, Name, TradeVolume, TradeValue, OpeningPrice, HighestPrice, LowestPrice, ClosingPrice
    for row in twse_data:
        try:
            code = row['Code']
            # â˜… ç¯©é¸ï¼š4ç¢¼ä¸”é¦–ä½é0 (æ’é™¤ ETF/æ¬Šè­‰)
            if len(code) != 4 or code.startswith('0'):
                continue

            # [Optimization] Whitelist Check
            if valid_whitelist is not None and code not in valid_whitelist:
                continue

            # æ—¥æœŸè½‰è¥¿å…ƒ (TWSE çµ¦çš„æ˜¯æ°‘åœ‹ 1131224)
            d_str = row['Date'] # 1131224
            y = int(d_str[:3]) + 1911
            m = d_str[3:5]
            d = d_str[5:7]
            date_ad = f"{y}-{m}-{d}"
            
            # æ•¸å€¼è™•ç† (å»é™¤é€—è™Ÿ)
            vol = float(row['TradeVolume'].replace(',', ''))
            op = float(row['OpeningPrice'].replace(',', ''))
            hi = float(row['HighestPrice'].replace(',', ''))
            lo = float(row['LowestPrice'].replace(',', ''))
            cl = float(row['ClosingPrice'].replace(',', ''))
            
            # Calculate Amount
            amount = cl * vol
            
            # å­˜æ“‹
            save_to_csv(code, date_ad, op, hi, lo, cl, vol, amount)
            updated_count += 1
        except:
            pass
            
    # è™•ç† TPEx (Open API)
    # JSON Keys: Date, SecuritiesCompanyCode, Close, Open, High, Low, TradingShares
    for row in tpex_data:
        try:
            code = row['SecuritiesCompanyCode']
            
            # â˜… ç¯©é¸ï¼š4ç¢¼ä¸”é¦–ä½é0 (æ’é™¤ ETF/æ¬Šè­‰)
            if len(code) != 4 or code.startswith('0'):
                continue

            # [Optimization] Whitelist Check
            if valid_whitelist is not None and code not in valid_whitelist:
                continue

            # æ—¥æœŸè½‰è¥¿å…ƒ (TPEx Open API çµ¦çš„æ˜¯æ°‘åœ‹ 1141224)
            d_str = row['Date']
            y = int(d_str[:3]) + 1911
            m = d_str[3:5]
            d = d_str[5:7]
            date_ad = f"{y}-{m}-{d}"
            
            cl = float(row['Close'])
            op = float(row['Open'])
            hi = float(row['High'])
            lo = float(row['Low'])
            vol = float(row['TradingShares']) # å·²ç¶“æ˜¯è‚¡æ•¸
            
            # æ’é™¤ç„¡äº¤æ˜“ (---)
            if str(cl) == '---' or  str(op) == '---': continue

            # Calculate Amount
            amount = cl * vol

            save_to_csv(code, date_ad, op, hi, lo, cl, vol, amount)
            updated_count += 1
        except:
            pass

    print(f"âœ… å®˜æ–¹è³‡æ–™æ›´æ–°å®Œæˆï¼å…±è™•ç† {updated_count} æª”ã€‚")
    
    # å»ºç«‹å·²æ›´æ–°æ¸…å–® (Set)
    updated_codes = set()
    for row in twse_data:
        updated_codes.add(row.get('Code', '').strip())
    for row in tpex_data:
        updated_codes.add(row.get('SecuritiesCompanyCode', '').strip())
        
    return updated_codes

def save_to_csv(code, date_str, op, hi, lo, cl, vol, amount=None):
    """ å°‡å–®ç­†è³‡æ–™ Append åˆ° CSV """
    file_path = os.path.join(DATA_FOLDER, f"{code}.csv")
    
    # è¨ˆç®— Amount å¦‚æœæœªæä¾›
    if amount is None:
        try:
            amount = float(cl) * float(vol)
        except:
            amount = 0.0

    # å¦‚æœæª”æ¡ˆä¸å­˜åœ¨ï¼Œè‡ªå‹•å»ºç«‹ä¸¦å¯«å…¥ Header
    if not os.path.exists(file_path):
        print(f"ğŸ†• ç™¼ç¾æ–°è‚¡ç¥¨: {code}ï¼Œå»ºç«‹æª”æ¡ˆä¸­...")
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("Date,Open,High,Low,Close,Volume,Amount\n")

    # è®€å–æœ€å¾Œä¸€è¡Œæª¢æŸ¥æ—¥æœŸå’Œè³‡æ–™é‡è¤‡
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            if len(lines) > 1:
                last_line = lines[-1].strip()
                parts = last_line.split(',')
                last_date = parts[0]
                if last_date == date_str:
                    return "SKIPPED"  # æ—¥æœŸå®Œå…¨ç›¸åŒï¼Œè·³é
                # é˜²æ­¢å‡è³‡æ–™ï¼šå¦‚æœ OHLCV èˆ‡æœ€å¾Œä¸€è¡Œå®Œå…¨ä¸€è‡´ï¼ˆéäº¤æ˜“æ—¥é‡è¤‡ï¼‰ï¼Œä¹Ÿè·³é
                if len(parts) >= 6:
                    try:
                        last_ohlcv = (float(parts[1]), float(parts[2]), float(parts[3]), float(parts[4]), float(parts[5]))
                        new_ohlcv = (float(op), float(hi), float(lo), float(cl), float(vol))
                        if last_ohlcv == new_ohlcv:
                            return "SKIPPED"  # OHLCV å®Œå…¨ä¸€è‡´ = éäº¤æ˜“æ—¥å‡è³‡æ–™
                    except:
                        pass
    except:
        pass

    # Append å¯«å…¥
    # æ ¼å¼: Date, Open, High, Low, Close, Volume, Amount
    new_line = f"{date_str},{op},{hi},{lo},{cl},{vol},{amount:.2f}\n"
    try:
        with open(file_path, 'a', encoding='utf-8') as f:
            f.write(new_line)
            f.flush()
            os.fsync(f.fileno())
        if code == "2330": print("   [DEBUG] 2330 Written & Flushed.")
        return True
    except Exception as e:
        print(f"âŒ Write Error {code}: {e}")
        return False

def update_from_histock(already_updated_codes, valid_whitelist=None):
    """
    å¾ HiStock æŠ“å–å…¨å¸‚å ´è¡Œæƒ… (ä½œç‚ºç¬¬äºŒé“é˜²ç·š)
    valid_whitelist: åƒ…å…è¨±æ›´æ–°çš„è‚¡ç¥¨ä»£è™Ÿé›†åˆ (Strict Filter)
    """
    print("\nğŸ“¡ 2. é€£ç·šè‡³ HiStock (é€šç”¨å‚™æ´æ©Ÿåˆ¶)...")
    url = "https://histock.tw/stock/rank.aspx?p=all"
    
    updated_count = 0
    new_updated_codes = set()
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
        }
        r = requests.get(url, headers=headers, timeout=30)
        r.encoding = 'utf-8' # HiStock is usually UTF-8
        
        if r.status_code != 200:
            print(f"   âŒ HiStock é€£ç·šå¤±æ•—: {r.status_code}")
            return new_updated_codes

        # Parse HTML Table
        dfs = pd.read_html(StringIO(r.text))
        target_df = None
        for df in dfs:
            # Check cols
            cols = [str(c) for c in df.columns]
            if any("ä»£è™Ÿ" in c for c in cols) and any("åƒ¹æ ¼" in c for c in cols):
                target_df = df
                break
        
        if target_df is None:
            print("   âŒ è§£æå¤±æ•—: æ‰¾ä¸åˆ°ç›®æ¨™è¡¨æ ¼")
            return new_updated_codes

        # Debug: Print columns
        # print(f"   Table Columns: {target_df.columns.tolist()}")

        # Clean columns: remove spaces, newlines, and sort arrows
        clean_cols = []
        for c in target_df.columns:
            clean_cols.append(str(c).strip().replace(" ", "").replace("\n", "").replace("â–¼", ""))
        target_df.columns = clean_cols
        
        # Verify 'ä»£è™Ÿ' exists exactly
        if 'ä»£è™Ÿ' not in target_df.columns:
            # Try to find which column is code
            # usually col 0
            if 'ä»£è™Ÿ' in str(target_df.columns[0]):
                target_df.rename(columns={target_df.columns[0]: 'ä»£è™Ÿ'}, inplace=True)
            else:
                print(f"   âŒ æ‰¾ä¸åˆ° 'ä»£è™Ÿ' æ¬„ä½. Columns: {target_df.columns}")
                return new_updated_codes

        today_ad = datetime.now().strftime('%Y-%m-%d')
        
        processed_df = target_df[target_df['ä»£è™Ÿ'].astype(str).str.len() == 4] # Filter broadly first
        
        print(f"   ğŸ” HiStock æŠ“åˆ° {len(processed_df)} ç­†è³‡æ–™ï¼Œæ­£åœ¨ç¯©é¸èˆ‡å¯«å…¥...")

        for idx, row in processed_df.iterrows():
            try:
                code_raw = str(row['ä»£è™Ÿ']).strip()
                # åš´æ ¼ç¯©é¸
                if len(code_raw) != 4 or code_raw.startswith('0') or not code_raw.isdigit():
                    continue
                
                # [Optimization] Whitelist Check
                if valid_whitelist is not None:
                    if code_raw not in valid_whitelist:
                        continue
                
                # Check if already updated by Official (Set check is fast)
                if code_raw in already_updated_codes:
                    continue

                # Extract Data
                # Note: HiStock uses '-' for no data?
                def parse_val(v):
                    s = str(v).replace(',', '').strip()
                    if s == '--' or s == '': return None
                    try: return float(s)
                    except: return None
                
                # Column names might differ slightly (e.g. 'åƒ¹æ ¼' vs 'æˆäº¤')
                # Strict Mapping based on User Screenshot:
                # [ä»£è™Ÿ, åç¨±, åƒ¹æ ¼, æ¼²è·Œ, æ¼²è·Œå¹…, å‘¨æ¼²è·Œ, æŒ¯å¹…, é–‹ç›¤, æœ€é«˜, æœ€ä½, æ˜¨æ”¶, æˆäº¤é‡, æˆäº¤å€¼(å„„)]
                # We need: åƒ¹æ ¼(Close), é–‹ç›¤(Open), æœ€é«˜(High), æœ€ä½(Low), æˆäº¤é‡(Volume), æˆäº¤å€¼(å„„)(Amount)
                
                # Check exact keys from screenshot (after cleaning 'â–¼')
                cl = parse_val(row.get('åƒ¹æ ¼')) or parse_val(row.get('æˆäº¤'))
                op = parse_val(row.get('é–‹ç›¤')) or cl
                hi = parse_val(row.get('æœ€é«˜')) or cl
                lo = parse_val(row.get('æœ€ä½')) or cl
                vol_lots = parse_val(row.get('æˆäº¤é‡'))
                amount_å„„ = parse_val(row.get('æˆäº¤å€¼(å„„)'))
                
                if cl is None: continue
                if op is None: op = cl
                if hi is None: hi = cl
                if lo is None: lo = cl
                if vol_lots is None: vol_lots = 0
                
                vol_shares = int(vol_lots * 1000)
                
                # å„ªå…ˆä½¿ç”¨ HiStock çš„æˆäº¤å€¼(å„„),å¦‚æœæ²’æœ‰æ‰ç”¨è¨ˆç®—æ–¹å¼
                if amount_å„„ is not None and amount_å„„ > 0:
                    amount = float(amount_å„„) * 100000000  # å„„è½‰æ›ç‚ºå…ƒ
                else:
                    amount = float(cl) * vol_shares  # å‚™ç”¨è¨ˆç®—æ–¹å¼
                
                # Save
                if code_raw == "2330":
                    print(f"[DEBUG] Processing 2330: Price={cl}, Vol={vol_shares}, Amt={amount}, Date={today_ad}")
                
                status_save = save_to_csv(code_raw, today_ad, op, hi, lo, cl, vol_shares, amount)
                
                if status_save is False: 
                    # Error occurred
                    continue
                
                new_updated_codes.add(code_raw)
                
                if status_save == "SKIPPED":
                    # Skipped due to up-to-date, but track it as processed
                    continue
                    
                if code_raw == "2330":
                    print(f"[DEBUG] 2330 Save Status: {status_save}")

                updated_count += 1
                new_updated_codes.add(code_raw)
                
            except Exception as inner_e:
                print(f"Row Error {code_raw}: {inner_e}")
                continue

        print(f"   âœ… HiStock æ›´æ–°å®Œæˆï¼å…±è£œè¶³ {updated_count} æª”ã€‚")
        
    except Exception as e:
        print(f"   âŒ HiStock åŸ·è¡ŒéŒ¯èª¤: {e}")
        
    return new_updated_codes

# ================= ä¸»ç¨‹å¼ =================
if __name__ == "__main__":
    # å¼·åˆ¶å°‡è¼¸å‡ºç·¨ç¢¼è¨­ç‚º utf-8 (è§£æ±º Windows Emoji å ±éŒ¯)
    sys.stdout.reconfigure(encoding='utf-8')

    ensure_folder_exists()

    # Optimization: Check success marker
    SUCCESS_MARKER = os.path.join(DATA_FOLDER, ".update_success")
    if os.path.exists(SUCCESS_MARKER):
        mtime = datetime.fromtimestamp(os.path.getmtime(SUCCESS_MARKER))
        if mtime.date() == datetime.now().date():
             print(f"âœ… [Pipeline] ä»Šæ—¥ ({mtime.date()}) è³‡æ–™å·²æ›´æ–°å®Œæˆï¼Œè·³éåŸ·è¡Œã€‚")
             sys.exit(0)

    today_ad = datetime.now().strftime('%Y-%m-%d')
    print(f"âœ… ä»Šæ—¥æ—¥æœŸ: {today_ad}")

    # 1. å–å¾—ç›®æ¨™è‚¡ç¥¨æ¸…å–® (HiStock)
    histock_list = get_stock_list_universal()
    
    # [Consistency Fix] Filter by MoneyDJ List
    dj_codes = set()
    dj_file = os.path.join(META_FOLDER, "moneydj_industries.csv")
    if os.path.exists(dj_file):
        try:
            with open(dj_file, 'r', encoding='utf-8-sig') as f:
                lines = f.readlines()
                start_idx = 0
                if lines and "Code" in lines[0] and "Name" in lines[0]: start_idx=1
                for line in lines[start_idx:]:
                    p = line.split(',')
                    if len(p)>=1: 
                        c=p[0].strip()
                        if c: dj_codes.add(c)
            print(f"ğŸ“‹ MoneyDJ æ¸…å–®é™åˆ¶: {len(dj_codes)} æª”")
            
            # Intersection
            all_stocks = sorted(list(set(histock_list) & dj_codes))
            print(f"âš ï¸ éæ¿¾å¾Œç›®æ¨™è‚¡ç¥¨: {len(all_stocks)} æª” (åŸ {len(histock_list)} æª”)")
        except Exception as e:
            print(f"âŒ è®€å– MoneyDJ æ¸…å–®éŒ¯èª¤: {e}, ä½¿ç”¨å…¨éƒ¨æ¸…å–®")
            all_stocks = histock_list
    else:
        print("âš ï¸ ç„¡ MoneyDJ æ¸…å–®ï¼Œä½¿ç”¨ HiStock å…¨éƒ¨è‚¡ç¥¨")
        all_stocks = histock_list

    print(f"ğŸ“‹ æœ€çµ‚æ›´æ–°ç›®æ¨™: {len(all_stocks)} æª”")

    today_str = datetime.now().strftime('%Y-%m-%d')
    print(f"ğŸ“… åŸ·è¡Œæ—¥æœŸ: {today_str}")

    # 2. â˜… å„ªå…ˆï¼šHiStock (User Request Preferred Source)
    print("\nğŸš€ å•Ÿå‹• Step 1: HiStock çˆ¬èŸ² (å„ªå…ˆä¾†æº)...")
    # strict_whitelist = all_stocks (only these are allowed)
    updated_codes = update_from_histock(set(), valid_whitelist=set(all_stocks))
    
    # 3. â˜… æ¬¡è¦ï¼šå®˜æ–¹é›™åˆ€æµ (TWSE + TPEx)
    print("\nğŸš€ å•Ÿå‹• Step 2: å®˜æ–¹é›™åˆ€æµ (TWSE+TPEx) (è£œè¶³ HiStock ç¼ºæ¼)...")
    # Official function returns False if completely failed, or a set if succeeded
    force_mode = "--force" in sys.argv
    official_res = update_daily_official(valid_whitelist=set(all_stocks), force=force_mode)
    
    if official_res is not False:
        updated_codes.update(official_res)
    else:
        print("âš ï¸ å®˜æ–¹ä¾†æºç„¡ä»»ä½•è³‡æ–™ (å¯èƒ½ç‚ºéäº¤æ˜“æ—¥æˆ–APIç•°å¸¸)ã€‚")

    # 4. â˜… æœ€å¾Œé˜²ç·šï¼šFinMind è£œæ¼
    # è¨ˆç®—å‰©ä¸‹æ²’æ›´æ–°çš„
    missing_stocks = []
    for stock in all_stocks:
        if stock not in updated_codes:
            missing_stocks.append(stock)
    
    if len(missing_stocks) > 0:
        print(f"\nâš ï¸ ç™¼ç¾ {len(missing_stocks)} æª”è‚¡ç¥¨å°šæœªæ›´æ–°ï¼Œå•Ÿå‹• FinMind è£œæ•‘æ©Ÿåˆ¶...")
        # åƒ…é¡¯ç¤ºå‰ 10 æª”ç¯„ä¾‹
        print(f"   (Pending: {missing_stocks[:10]} ...)")
        
        # å‘¼å« FinMind ä¸‹è¼‰å™¨ (orchestrate_update)
        # æ³¨æ„: FinMind éœ€è¦ Token
        orchestrate_update(missing_stocks)
    else:
        print("\nğŸ‰ å®Œç¾ï¼æ‰€æœ‰ç›®æ¨™è‚¡ç¥¨çš†å·²é€é HiStock/å®˜æ–¹ ä¾†æºæ›´æ–°ã€‚")

    # 5. â˜… ç¨ç«‹ä»»å‹™ï¼šæ›´æ–°å¤§ç›¤ (TAIEX)
    print("\nğŸ“Š æ­£åœ¨æ›´æ–°å¤§ç›¤ (TAIEX) è³‡æ–™...")
    taiex_updated = False
    for token in API_KEYS:
        try:
            url = "https://api.finmindtrade.com/api/v4/data"
            p = {
                "dataset": "TaiwanStockPrice",
                "data_id": "TAIEX",
                "start_date": "2000-01-01",
                "token": token
            }
            res = requests.get(url, params=p, timeout=15)
            if res.status_code == 200:
                data = res.json().get('data', [])
                if data:
                    df = pd.DataFrame(data)
                    df = df[['date', 'open', 'max', 'min', 'close', 'Trading_Volume']]
                    df.columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume']
                    
                    csv_path = os.path.join(DATA_FOLDER, "..", "TAIEX.csv")
                    df.to_csv(csv_path, index=False, encoding='utf-8')
                    print(f"âœ… å¤§ç›¤è³‡æ–™å·²æ›´æ–°: {csv_path}")
                    taiex_updated = True
                    break
        except Exception as e:
            print(f"âš ï¸ å¤§ç›¤æ›´æ–°å¤±æ•— ({token[-4:]}): {e}")
            continue
            
    if not taiex_updated:
        print("âŒ å¤§ç›¤è³‡æ–™æ›´æ–°å¤±æ•— (æ‰€æœ‰ Token çš†ç„¡æ•ˆ)")
    else:
        # Mark as success only if TAIEX (and logically others) finished
        with open(SUCCESS_MARKER, 'w') as f:
             f.write(f"Updated at {datetime.now()}")
        print("âœ… å…¨æµç¨‹å®Œæˆï¼Œå·²å»ºç«‹æˆåŠŸæ¨™è¨˜ (.update_success)ã€‚")
