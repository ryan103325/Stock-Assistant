"""
ä¸€æ¬¡æ€§ä¿®å¾©è…³æœ¬ï¼š
1. å¾ FinMind æŠ“å–å®Œæ•´ TAIEX (2020-07-01 ~ today)
2. æˆªæ–· history/*.csv ä¸­ 2020-07-01 ä¹‹å‰çš„è³‡æ–™
3. åŸ·è¡Œ Pipeline è£œé½Šåˆ°æœ€æ–°æ—¥æœŸ
4. é©—è­‰è³‡æ–™å®Œæ•´æ€§
"""
import os
import sys
import glob
import requests
import pandas as pd
from datetime import datetime
from dotenv import load_dotenv

sys.stdout.reconfigure(encoding='utf-8')
load_dotenv()

SRC_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
DATA_FOLDER = os.path.join(SRC_ROOT, "data_core", "history")
TAIEX_PATH = os.path.join(SRC_ROOT, "data_core", "TAIEX.csv")
CUTOFF_DATE = "2020-07-01"
TOKEN = os.getenv("FINMIND_TOKEN", "")

def step1_fix_taiex():
    """å¾ FinMind æŠ“å–å®Œæ•´ TAIEX è³‡æ–™"""
    print("\n" + "="*60)
    print("ğŸ“Š Step 1: æ›´æ–° TAIEX.csv (2020-07-01 ~ today)")
    print("="*60)
    
    if not TOKEN:
        print("âŒ æ²’æœ‰ FINMIND_TOKENï¼Œç„¡æ³•æŠ“å– TAIEX")
        return False
    
    url = "https://api.finmindtrade.com/api/v4/data"
    params = {
        "dataset": "TaiwanStockPrice",
        "data_id": "TAIEX",
        "start_date": CUTOFF_DATE,
        "token": TOKEN
    }
    
    print(f"ğŸ“¡ æ­£åœ¨å¾ FinMind æŠ“å– TAIEX ({CUTOFF_DATE} ~ today)...")
    try:
        resp = requests.get(url, params=params, timeout=30)
        data = resp.json().get('data', [])
        
        if not data:
            print("âŒ æ²’æœ‰å›å‚³è³‡æ–™")
            return False
        
        df = pd.DataFrame(data)
        df = df.rename(columns={
            'date': 'Date', 'open': 'Open', 'max': 'High',
            'min': 'Low', 'close': 'Close', 'Trading_Volume': 'Volume'
        })
        df = df[['Date', 'Open', 'High', 'Low', 'Close', 'Volume']]
        df = df.drop_duplicates(subset=['Date'], keep='last')
        df = df.sort_values('Date').reset_index(drop=True)
        
        df.to_csv(TAIEX_PATH, index=False, encoding='utf-8')
        print(f"âœ… TAIEX æ›´æ–°å®Œæˆï¼")
        print(f"   ç¯„åœ: {df.iloc[0]['Date']} ~ {df.iloc[-1]['Date']}")
        print(f"   ç­†æ•¸: {len(df)}")
        return True
    except Exception as e:
        print(f"âŒ TAIEX æ›´æ–°å¤±æ•—: {e}")
        return False

def step2_trim_history():
    """æˆªæ–· history ä¸­ 2020-07-01 ä¹‹å‰çš„è³‡æ–™"""
    print("\n" + "="*60)
    print(f"âœ‚ï¸ Step 2: æˆªæ–· history/*.csv ({CUTOFF_DATE} ä¹‹å‰çš„è³‡æ–™)")
    print("="*60)
    
    csv_files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))
    print(f"ğŸ“ æ‰¾åˆ° {len(csv_files)} å€‹ CSV æª”æ¡ˆ")
    
    trimmed_count = 0
    error_count = 0
    
    for i, f in enumerate(csv_files):
        try:
            df = pd.read_csv(f)
            if 'Date' not in df.columns:
                continue
            
            original_len = len(df)
            df = df[df['Date'] >= CUTOFF_DATE]
            df = df.drop_duplicates(subset=['Date'], keep='last')
            df = df.sort_values('Date').reset_index(drop=True)
            
            if len(df) < original_len:
                df.to_csv(f, index=False)
                trimmed_count += 1
            
            if (i + 1) % 200 == 0:
                print(f"   å·²è™•ç† {i+1}/{len(csv_files)}...")
        except Exception as e:
            error_count += 1
            if error_count <= 5:
                stock_id = os.path.basename(f).replace('.csv', '')
                print(f"   âš ï¸ {stock_id}: {e}")
    
    print(f"âœ… æˆªæ–·å®Œæˆï¼ä¿®æ”¹ {trimmed_count} æª”ï¼ŒéŒ¯èª¤ {error_count} æª”")

def step3_verify():
    """é©—è­‰è³‡æ–™å®Œæ•´æ€§"""
    print("\n" + "="*60)
    print("ğŸ” Step 3: é©—è­‰è³‡æ–™å®Œæ•´æ€§")
    print("="*60)
    
    # é©—è­‰ TAIEX
    df_taiex = pd.read_csv(TAIEX_PATH)
    taiex_start = df_taiex.iloc[0]['Date']
    taiex_end = df_taiex.iloc[-1]['Date']
    print(f"ğŸ“Š TAIEX: {taiex_start} ~ {taiex_end} ({len(df_taiex)} ç­†)")
    
    if taiex_start > CUTOFF_DATE:
        print(f"   âš ï¸ TAIEX èµ·å§‹æ—¥ {taiex_start} æ™šæ–¼ {CUTOFF_DATE}")
    if taiex_end < "2026-02-10":
        print(f"   âš ï¸ TAIEX æœ€å¾Œæ—¥ {taiex_end} æ—©æ–¼ 2026-02-10")
    
    # æŠ½æ¨£é©—è­‰ history
    samples = ['2330', '2317', '2454', '2881', '1101', '3008', '2603']
    print(f"\nğŸ“‹ æŠ½æ¨£é©—è­‰ history:")
    
    missing_today = 0
    too_early = 0
    csv_files = glob.glob(os.path.join(DATA_FOLDER, "*.csv"))
    
    for f in csv_files:
        try:
            df = pd.read_csv(f)
            if 'Date' not in df.columns or len(df) == 0:
                continue
            sid = os.path.basename(f).replace('.csv', '')
            start = df.iloc[0]['Date']
            end = df.iloc[-1]['Date']
            
            if start < CUTOFF_DATE:
                too_early += 1
            if end < "2026-02-10":
                missing_today += 1
            
            if sid in samples:
                status = "âœ…" if (start >= CUTOFF_DATE and end >= "2026-02-10") else "âš ï¸"
                print(f"   {status} {sid}: {start} ~ {end} ({len(df)} ç­†)")
        except:
            pass
    
    print(f"\nğŸ“Š ç¸½çµ:")
    print(f"   æª”æ¡ˆç¸½æ•¸: {len(csv_files)}")
    print(f"   èµ·å§‹æ—¥æ—©æ–¼ {CUTOFF_DATE}: {too_early} æª”")
    print(f"   æœ€å¾Œæ—¥æ—©æ–¼ 2026-02-10: {missing_today} æª”")
    
    if missing_today > 0:
        print(f"\nğŸ’¡ æœ‰ {missing_today} æª”ç¼ºå°‘æœ€æ–°è³‡æ–™ï¼Œéœ€è¦åŸ·è¡Œ Pipeline è£œé½Š")
        print(f"   è«‹åŸ·è¡Œ: python src/tools/data_pipeline/Pipeline_data.py --force")

if __name__ == "__main__":
    step1_fix_taiex()
    step2_trim_history()
    step3_verify()
    print("\nğŸ‰ å…¨éƒ¨å®Œæˆï¼")
