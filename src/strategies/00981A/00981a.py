from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import pandas as pd
import time
import os
import csv
from datetime import datetime, timedelta
import requests
from io import StringIO 
import re 
import sys 
from dotenv import load_dotenv
load_dotenv()

# æ—ç¾¤æ•´åˆæ¨¡çµ„ (ä½æ–¼ src/tools/tag_generator)
import sys
sys.path.insert(0, os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "tools", "tag_generator"))
from group_mapping import (
    get_stock_groups, 
    calculate_group_weights, 
    calculate_group_stock_changes,
    get_extended_group_mapping,
    find_unclassified_tags
)

# åœ–ç‰‡å ±å‘Šç”Ÿæˆå™¨
from report_generator_html import generate_fund_report_image

# ==========================================
# âš™ï¸ è¨­å®šå€
# ==========================================
tg_token = os.getenv("TELEGRAM_TOKEN", "")
tg_chat_id = os.getenv("TELEGRAM_CHAT_ID", "")

# æª¢æŸ¥ Token
if "ä½ çš„" in tg_token:
    CAN_SEND_TG = False
    print("âš ï¸ æœªè¨­å®š Tokenï¼Œå°‡åƒ…åŸ·è¡Œå­˜æª”ï¼Œä¸ç™¼é€é€šçŸ¥ã€‚")
else:
    CAN_SEND_TG = True

# è¨­å®šè·¯å¾‘
# è¨­å®šè·¯å¾‘
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) # src/ç­–ç•¥åº«/00981a_åŸºé‡‘ -> src/ç­–ç•¥åº« -> src
# Correction: current file is in src/ç­–ç•¥åº«/00981a_åŸºé‡‘
# dirname -> src/ç­–ç•¥åº«
# dirname -> src
# So 2 dirnames is correct if file is 2 levels deep from src?
# No. src/ç­–ç•¥åº«/00981a_åŸºé‡‘/00981a.py.
# dirname(abspath) -> src/ç­–ç•¥åº«/00981a_åŸºé‡‘
# dirname -> src/ç­–ç•¥åº«
# dirname -> src
# So 3 dirnames needed? No, wait.
# OLD: src/reports/00981a.py. 2 levels deep.
# NEW: src/ç­–ç•¥åº«/00981a_åŸºé‡‘/00981a.py. 3 levels deep?
# Let's count slash: src/reports/file (2 dirs). src/ç­–ç•¥åº«/00981a_åŸºé‡‘/file (3 dirs).
# So I need one more dirname.

SRC_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

DATA_FOLDER = os.path.join(SRC_ROOT, "data_core", "history")
CACHE_FILE = os.path.join(SRC_ROOT, "cache", "market_matrix.pkl")
HISTORY_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "fund_holdings_history.csv")
TREND_LOG = os.path.join(os.path.dirname(os.path.abspath(__file__)), "fund_trend_log.csv")
CONCEPT_HISTORY_FILE = os.path.join(os.path.dirname(os.path.abspath(__file__)), "fund_concept_history.csv")

# ä½¿ç”¨å…¨åŸŸè·¯å¾‘è¨­å®š
trend_filename = TREND_LOG
holdings_filename = HISTORY_FILE
concept_filename = CONCEPT_HISTORY_FILE

# Optimization: Check if output already exists for today
if os.path.exists(trend_filename):
    try:
        df_check = pd.read_csv(trend_filename)
        if not df_check.empty:
            last_date = str(df_check.iloc[-1]['æ—¥æœŸ'])
            today_str = datetime.now().strftime('%Y-%m-%d')
            if last_date == today_str:
                print(f"âœ… [00981a] ä»Šæ—¥ ({today_str}) å·²ç”¢ç”Ÿå ±å‘Šï¼Œè·³éåŸ·è¡Œã€‚")
                sys.exit(0)
    except Exception as e:
        print(f"âš ï¸ æª¢æŸ¥èˆŠæª”å¤±æ•—: {e}")

# ==========================================
# ğŸ§  æ ¸å¿ƒæ¼”ç®—æ³•
# ==========================================
def analyze_flow_impact(sub_payable, red_payable, net_assets, cash, sp_ratio):
    """
    è¼¸å…¥:
    - sub_payable: ç”³è³¼æ‡‰ä»˜æ¬¾ (é€šå¸¸ç‚ºè² å€¼ï¼Œä»£è¡¨æ¬ æŠ•è³‡äººæ†‘è­‰ï¼Œä½†æ‰‹ä¸Šæœ‰ç¾é‡‘)
    - red_payable: è´–å›æ‡‰ä»˜æ¬¾ (é€šå¸¸ç‚ºæ­£å€¼ï¼Œä»£è¡¨æ¬ æŠ•è³‡äººç¾é‡‘)
    - net_assets: æ·¨è³‡ç”¢
    - cash: æ‰‹ä¸Šç¾é‡‘
    - sp_ratio: è²·è³£å‹•ä½œ (è² è²·æ­£è³£)
    """
    
    # å–çµ•å°å€¼ä»¥é˜²è¬ä¸€ (æœƒè¨ˆç§‘ç›®æ­£è² è™Ÿæœ‰æ™‚ä¸åŒ)
    sub_val = abs(sub_payable)
    red_val = abs(red_payable)

    # 1. è¨ˆç®—æ¯”ç‡
    # ç”³è³¼ç‡ï¼šæ–°é€²ä¾†çš„éŒ¢ä½”æ·¨è³‡ç”¢å¤šå°‘ï¼Ÿ(è¶…é 1% é€šå¸¸å°±æ˜¯å¤§é¡)
    sub_ratio = (sub_val / net_assets) * 100
    
    # è´–å›é¢¨éšªå€¼ï¼šè¦ä»˜å‡ºå»çš„éŒ¢ä½”ç¾é‡‘å¤šå°‘ï¼Ÿ(è¶…é 50% å¾ˆå±éšª)
    # å¦‚æœç¾é‡‘æ˜¯ 0ï¼Œè¨­ç‚ºç„¡é™å¤§é¢¨éšª
    liquidity_risk = (red_val / cash * 100) if cash > 0 else 999 

    flow_signal = "NORMAL"
    flow_desc = "è³‡é‡‘æµå‘æ­£å¸¸"

    # 2. åˆ¤æ–·é‚è¼¯
    # ã€æœ€å„ªå…ˆã€‘åˆ¤æ–·è´–å›å±æ©Ÿ (æ•‘å‘½è¨Šè™Ÿ)
    if liquidity_risk > 80:
        flow_signal = "CRISIS"
        flow_desc = "ğŸ’€ æµå‹•æ€§å±æ©Ÿ (è´–å› > ç¾é‡‘ï¼Œè¢«è¿«æ®ºå‡º)"
    elif liquidity_risk > 50:
        flow_signal = "WARNING"
        flow_desc = "âš ï¸ è´–å›å£“åŠ›å¤§ (ç¾é‡‘åƒç·Š)"

    # ã€æ¬¡è¦ã€‘åˆ¤æ–·ç”³è³¼å‹•èƒ½ (å¦‚æœæœ‰æ–°éŒ¢é€²ä¾†)
    elif sub_ratio > 0.8: # é–€æª»å¯è‡ªè¡Œèª¿æ•´ï¼Œé€šå¸¸ 0.8%~1% ç®—é¡¯è‘—
        if sp_ratio < -0.2:
            flow_signal = "PARTY"
            flow_desc = "ğŸš€ è³‡é‡‘æ´¾å° (æ•£æˆ¶æ¹§å…¥ + ç¶“ç†äººåŠ ç¢¼)"
        elif sp_ratio > 0.5:
            flow_signal = "DUMP"
            flow_desc = "ğŸ“‰ è¶æ©Ÿå€’è²¨ (æ”¶åˆ°ç”³è³¼æ¬¾å»åœ¨è³£è‚¡)"
        else:
            flow_signal = "SUPPORT"
            flow_desc = "ğŸ¢ æ½›åœ¨è²·ç›¤ (æ–°è³‡é‡‘å¾…é€²å ´)"
            
    return flow_signal, flow_desc, sub_ratio

def get_comprehensive_alert(fund_data):
    """
    è¼¸å…¥ fund_data å­—å…¸ï¼ŒåŒ…å«:
    net_assets, cash, settlement, stock_value, futures_nominal,
    sub_payable (ç”³è³¼), red_payable (è´–å›)
    """
    # 1. è§£å£“ç¸®æ•¸æ“š
    net = fund_data['net_assets']
    cash = fund_data['cash']
    settlement = fund_data['settlement']
    stock = fund_data['stock_value']
    futures = fund_data.get('futures_nominal', 0)
    sub_pay = fund_data.get('sub_payable', 0)
    red_pay = fund_data.get('red_payable', 0)

    if net == 0: return { "Final_Alert": "âš ï¸ æ•¸æ“šç•°å¸¸", "Total_Exposure": 0, "SP_Ratio": 0, "Flow_Desc": "N/A" }

    # 2. è¨ˆç®—é—œéµæŒ‡æ¨™
    total_exposure = ((stock + futures) / net) * 100  # ç¸½æ›éšª
    sp_ratio = (settlement / net) * 100               # å‹•ä½œ (è² è²·æ­£è³£)
    
    # å‘¼å«ä¸Šé¢çš„æµå‘åˆ†æ
    flow_sig, flow_desc, sub_ratio = analyze_flow_impact(sub_pay, red_pay, net, cash, sp_ratio)

    # 3. ğŸ›¡ï¸ æœ€çµ‚è­¦ç¤ºåˆ¤å®šé‚è¼¯ (åˆ†å±¤åˆ¤æ–·)
    alert_survival = ""
    alert_momentum = ""
    alert_operation = ""
    
    # (A) ç”Ÿå­˜å±¤ç´š (Survival)
    if flow_sig == "CRISIS":
        alert_survival = f"ğŸ’€ {flow_desc}"
    elif flow_sig == "WARNING":
        alert_survival = f"âš ï¸ {flow_desc}"
        
    # (B) å‹•èƒ½å±¤ç´š (Momentum)
    if flow_sig == "PARTY":
        alert_momentum = flow_desc  # flow_desc å·²å« emoji
    elif flow_sig == "DUMP":
        alert_momentum = flow_desc
    elif flow_sig == "SUPPORT":
        alert_momentum = flow_desc
    else:
        # å¦‚æœæ²’æœ‰ç‰¹æ®Šå‹•èƒ½ï¼Œé¡¯ç¤º Normal å—ï¼Ÿæˆ–æ˜¯ç©ºï¼Ÿ
        # User wants "Momentum and Operation levels to be listed".
        # If normal, maybe "â¡ï¸ è³‡é‡‘æµå‘æ­£å¸¸"
        if flow_sig == "NORMAL":
            alert_momentum = "â¡ï¸ è³‡é‡‘æµå‘æ­£å¸¸"

    # (C) æ“ä½œå±¤ç´š (Operation)
    # ç©æ¥µçœ‹å¤šå€
    if total_exposure > 100:
        alert_operation = "ğŸ”´ å…¨åŠ›é€²æ”» (æ§“æ¡¿/è¿½åƒ¹)"
    elif total_exposure > 92 and sp_ratio < -0.5:
        alert_operation = "ğŸ”´ å¼·åŠ›è²·é€² (é«˜æŒè‚¡çºŒè²·)"
    
    # ç²åˆ©äº†çµå€
    elif total_exposure > 90 and sp_ratio > 0.5:
        alert_operation = "ğŸŸ  é«˜æª”ç²åˆ©äº†çµ (è¦‹å¥½å°±æ”¶)"
    
    # æŠ„åº•å€
    elif total_exposure < 88 and sp_ratio < -0.5:
        alert_operation = "ğŸŸ¢ ä½æª”ä½ˆå±€ (æŠ„åº•/å›è£œ)"
        
    # é˜²ç¦¦å€
    elif total_exposure < 82:
        alert_operation = "ğŸ”µ é˜²ç¦¦é¿éšª (ç¾é‡‘ç‚ºç‹)"
    elif total_exposure < 88 and sp_ratio > 0.5:
        alert_operation = "ğŸ”µ ä¿å®ˆæ¸›ç¢¼ (çœ‹å£å¾Œå¸‚)"
        
    # è§€æœ›å€
    else:
        alert_operation = "âšª è§€æœ›/çºŒæŠ± (ç›¤æ•´)"

    # 4. æ±ºå®šæœ€çµ‚æ¨™é¡Œ (Header) - å–æœ€åš´é‡çš„
    if alert_survival:
        final_header = alert_survival
    elif "ğŸš€" in alert_momentum or "ğŸ“‰" in alert_momentum:
        final_header = alert_momentum
    else:
        final_header = alert_operation

    # 4. å›å‚³å®Œæ•´åˆ†æåŒ…
    return {
        "Final_Alert": final_header,     # æ¨™é¡Œ
        "Survival": alert_survival,      # ç”Ÿå­˜å±¤ç´š
        "Momentum": alert_momentum,      # å‹•èƒ½å±¤ç´š
        "Operation": alert_operation,    # æ“ä½œå±¤ç´š
        "Total_Exposure": total_exposure,
        "SP_Ratio": sp_ratio,
        "Flow_Desc": flow_desc           
    }

# ==========================================
# ğŸ§  å­˜æª”å‡½å¼
# ==========================================
def save_data_with_overwrite(file_path, new_df, date_col='æ—¥æœŸ', max_rows=50):
    target_date = str(new_df.iloc[0][date_col])
    final_df = new_df 

    if os.path.exists(file_path):
        try:
            old_df = pd.read_csv(file_path, dtype={date_col: str})
            if target_date in old_df[date_col].values:
                print(f"   â„¹ï¸ ç™¼ç¾èˆŠè³‡æ–™ ({target_date})ï¼Œè¦†è“‹æ›´æ–°...")
                old_df = old_df[old_df[date_col] != target_date]
                mode_msg = "è¦†è“‹æ›´æ–°"
            else:
                print(f"   â„¹ï¸ æ–°å¢è³‡æ–™ ({target_date})...")
                mode_msg = "æ–°å¢è³‡æ–™"
            final_df = pd.concat([old_df, new_df], ignore_index=True)
        except Exception as e:
            print(f"âš ï¸ è®€æª”å¤±æ•—ï¼Œé‡å»ºæª”æ¡ˆ: {e}")
            final_df = new_df
            mode_msg = "é‡å»ºæª”æ¡ˆ"
    else:
        mode_msg = "å»ºç«‹æ–°æª”"

    # è£åˆ‡è‡³æœ€è¿‘ max_rows ç­†
    if max_rows and len(final_df) > max_rows:
        before_count = len(final_df)
        final_df = final_df.tail(max_rows).reset_index(drop=True)
        print(f"   âœ‚ï¸ è³‡æ–™è£åˆ‡: {before_count} â†’ {len(final_df)} ç­† (ä¿ç•™æœ€è¿‘ {max_rows} ç­†)")

    try:
        final_df.to_csv(file_path, index=False, encoding='utf-8-sig')
        return mode_msg
    except PermissionError:
        print("\nâŒ ç„¡æ³•å¯«å…¥æª”æ¡ˆï¼è«‹é—œé–‰ Excelï¼")
        return None

def send_telegram_message(message):
    if not CAN_SEND_TG: return
    try:
        url = f"https://api.telegram.org/bot{tg_token}/sendMessage"
        payload = {"chat_id": tg_chat_id, "text": message}
        resp = requests.post(url, json=payload)
        if resp.status_code == 200: print("âœ… TG ç™¼é€æˆåŠŸ")
        else: print(f"âŒ TG ç™¼é€å¤±æ•—: {resp.text}")
    except Exception as e: print(f"âŒ TG éŒ¯èª¤: {e}")

def send_telegram_photo(photo_path, caption=""):
    """Telegram ç™¼é€åœ–ç‰‡"""
    if not CAN_SEND_TG: return
    try:
        url = f"https://api.telegram.org/bot{tg_token}/sendPhoto"
        with open(photo_path, 'rb') as photo:
            files = {'photo': photo}
            data = {'chat_id': tg_chat_id, 'caption': caption}
            resp = requests.post(url, files=files, data=data)
        if resp.status_code == 200: 
            print("âœ… TG åœ–ç‰‡ç™¼é€æˆåŠŸ")
        else: 
            print(f"âŒ TG åœ–ç‰‡ç™¼é€å¤±æ•—: {resp.text}")
    except Exception as e: 
        print(f"âŒ TG åœ–ç‰‡éŒ¯èª¤: {e}")

def check_trading_day():
    """æª¢æŸ¥ä»Šæ—¥æ˜¯å¦ç‚ºäº¤æ˜“æ—¥ (FinMind TaiwanStockTradingDate)"""
    print("ğŸ“… [FinMind] ç¢ºèªäº¤æ˜“æ—¥ä¸­...")
    today_str = datetime.now().strftime('%Y-%m-%d')
    token = os.getenv("FINMIND_TOKEN", "")
    
    if not token:
        print("âš ï¸ æœªè¨­å®š FINMIND_TOKENï¼Œæ”¹ç”¨å¹³æ—¥åˆ¤æ–·")
        if datetime.now().weekday() >= 5:
            print(f"ğŸ›‘ é€±æœ«åœæ­¢åŸ·è¡Œã€‚")
            return False
        return True
    
    try:
        url = "https://api.finmindtrade.com/api/v4/data"
        params = {
            "dataset": "TaiwanStockTradingDate",
            "start_date": today_str,
            "end_date": today_str,
            "token": token
        }
        resp = requests.get(url, params=params, timeout=20)
        data = resp.json()
        dates = [d['date'] for d in data.get('data', [])]
        if today_str in dates:
            print(f"âœ… æ˜¯äº¤æ˜“æ—¥: {today_str}")
            return True
        else:
            print(f"ğŸ’¤ éäº¤æ˜“æ—¥: {today_str}")
            return False
    except Exception as e:
        print(f"âš ï¸ API æŸ¥è©¢å¤±æ•—: {e}")
        if datetime.now().weekday() >= 5:
            print(f"ğŸ›‘ é€±æœ«åœæ­¢åŸ·è¡Œã€‚")
            return False
        print("âš ï¸ æŸ¥ç„¡è³‡æ–™ä½†ç‚ºå¹³æ—¥ï¼Œå¼·åˆ¶åŸ·è¡Œã€‚")
        return True

def get_taiex_change():
    """è®€å–å¤§ç›¤æ¼²è·Œå¹… (TAIEX.csv)"""
    print("ğŸ“ˆ [Local] è®€å–å¤§ç›¤è®ŠåŒ– (TAIEX.csv)...")
    try:
        taiex_path = os.path.join(SRC_ROOT, "data_core", "TAIEX.csv")
        if os.path.exists(taiex_path):
            df = pd.read_csv(taiex_path)
            if len(df) >= 2:
                last = df.iloc[-1]
                prev = df.iloc[-2]
                pct_change = ((last['Close'] - prev['Close']) / prev['Close']) * 100
                print(f"âœ… å¤§ç›¤æ¼²è·Œ: {pct_change:.2f}% (Date: {last['Date']})")
                return pct_change
            else:
                print("âš ï¸ TAIEX.csv è³‡æ–™ä¸è¶³å…©ç­†")
        else:
            print("âš ï¸ æ‰¾ä¸åˆ° TAIEX.csv")
        return 0.0
    except Exception as e:
        print(f"âš ï¸ å¤§ç›¤è®€å–éŒ¯èª¤: {e}")
        return 0.0

# ==========================================
# ğŸš€ ä¸»ç¨‹å¼
# ==========================================

# ç­–ç•¥ 1: ä½¿ç”¨ FinMind æª¢æŸ¥äº¤æ˜“æ—¥
today = datetime.now().strftime("%Y-%m-%d")
force_mode = "--force" in sys.argv

if not force_mode:
    if not check_trading_day():
        print("ğŸ˜´ éäº¤æ˜“æ—¥ï¼Œè·³éåŸ·è¡Œã€‚")
        sys.exit(0)
else:
    print("âš ï¸ [Force Mode] å¼·åˆ¶åŸ·è¡Œï¼Œè·³éäº¤æ˜“æ—¥æª¢æŸ¥ã€‚")

taiex_roi = get_taiex_change()

options = webdriver.ChromeOptions()
options.add_argument('--headless')
# Suppress logs
options.add_argument('--log-level=3')
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

try:
    print("ğŸš€ å•Ÿå‹•ç€è¦½å™¨...")
    driver.maximize_window()
    url = "https://www.ezmoney.com.tw/ETF/Fund/Info?fundCode=49YTW"
    driver.get(url)

    wait = WebDriverWait(driver, 15)
    print("â³ å‰å¾€é é¢...")
    portfolio_btn = wait.until(EC.element_to_be_clickable((By.LINK_TEXT, "åŸºé‡‘æŠ•è³‡çµ„åˆ")))
    portfolio_btn.click()
    time.sleep(3) 

    target_date = datetime.now().strftime('%Y-%m-%d')
    try:
        date_el = driver.find_element(By.XPATH, "//*[contains(text(), 'è³‡æ–™æ—¥æœŸ')]")
        match = re.search(r'(\d{4}/\d{2}/\d{2})', date_el.text)
        if match: target_date = match.group(1).replace('/', '-')
        print(f"ğŸ“… è³‡æ–™æ—¥æœŸ: {target_date}")
    except: pass

    net_assets_value = 0
    try:
        nav_el = driver.find_element(By.XPATH, "//td[contains(text(),'æ·¨è³‡ç”¢')]/following-sibling::td")
        clean_nav = nav_el.text.replace('NTD', '').replace(',', '').strip()
        net_assets_value = float(clean_nav)
        print(f"ğŸ’° æ·¨è³‡ç”¢: {net_assets_value:,.0f}")
    except: print("âš ï¸ ç„¡æ³•æŠ“å–æ·¨è³‡ç”¢ã€‚")

    for i in range(3):
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(1)

    print("ğŸ“¥ è§£æè¡¨æ ¼...")
    dfs = pd.read_html(StringIO(driver.page_source))
    summary_dfs = []
    holdings_df = None

    for index, df in enumerate(dfs):
        cols = str(df.columns)
        print(f"   ğŸ” Table {index} Columns: {cols}") # Debug Print
        
        if "é …ç›®" in cols and "æ¬Šé‡" in cols:
            if isinstance(df.columns, pd.MultiIndex): df.columns = df.columns.get_level_values(-1)
            summary_dfs.append(df)
        elif ("è‚¡ç¥¨åç¨±" in cols and "è‚¡æ•¸" in cols) or ("è‚¡ç¥¨åç¨±" in cols and "æ¬Šé‡" in cols):
            holdings_df = df.copy()
            if isinstance(holdings_df.columns, pd.MultiIndex): holdings_df.columns = holdings_df.columns.get_level_values(-1)
        elif len(df) > 20 and holdings_df is None:
            # Fallback: Assume the long table is the holdings table
            print("   âš ï¸ æ‰¾ä¸åˆ°æ¨™æº–æ¬„ä½ï¼Œå˜—è©¦ä½¿ç”¨ã€Œé•·è¡¨æ ¼ã€ä½œç‚ºæŒè‚¡æ¸…å–®...")
            holdings_df = df.copy()
            if isinstance(holdings_df.columns, pd.MultiIndex): holdings_df.columns = holdings_df.columns.get_level_values(-1)

    # ---------------------------
    # ä»»å‹™ A: è³‡é‡‘æ°´ä½
    # ---------------------------
    if summary_dfs:
        try:
            summary_df = pd.concat(summary_dfs, ignore_index=True)
            col_item = [c for c in summary_df.columns if "é …ç›®" in str(c)][0]
            col_weight = [c for c in summary_df.columns if "æ¬Šé‡" in str(c)][0]
            col_amt = [c for c in summary_df.columns if "é‡‘é¡" in str(c)][0]
            
            def clean_val(val):
                return float(str(val).replace('%','').replace('NTD','').replace(',','').strip() or 0)
            summary_df['clean_weight'] = summary_df[col_weight].apply(clean_val)
            summary_df['clean_amt'] = summary_df[col_amt].apply(clean_val)
            def get_data(keyword):
                rows = summary_df[summary_df[col_item].astype(str).str.contains(keyword, regex=False, na=False)]
                if not rows.empty: return rows.iloc[0]['clean_weight'], rows.iloc[0]['clean_amt']
                return 0.0, 0.0

            stock_pct, stock_amt = get_data("è‚¡ç¥¨")
            cash_pct, cash_amt = get_data("ç¾é‡‘")
            futures_pct, futures_amt = get_data("æœŸè²¨(åç›®æœ¬é‡‘)")
            receivable_pct, receivable_amt = get_data("æ‡‰æ”¶ä»˜è­‰åˆ¸æ¬¾")
            # åŸå§‹ "ç”³è´–æ‡‰ä»˜æ¬¾" é‡‘é¡
            raw_subs_amt = get_data("ç”³è´–æ‡‰ä»˜æ¬¾")[1] 
            raw_subs_pct = get_data("ç”³è´–æ‡‰ä»˜æ¬¾")[0]

            # æ‹†è§£ ç”³è³¼(è² ) èˆ‡ è´–å›(æ­£)
            # ç”³è³¼æ‡‰ä»˜æ¬¾ (é€šå¸¸ç‚ºè² å€¼, ä»£è¡¨æ¬ æŠ•è³‡äººæ†‘è­‰)
            sub_payable = raw_subs_amt if raw_subs_amt < 0 else 0
            # è´–å›æ‡‰ä»˜æ¬¾ (é€šå¸¸ç‚ºæ­£å€¼, ä»£è¡¨æ¬ æŠ•è³‡äººç¾é‡‘)
            red_payable = raw_subs_amt if raw_subs_amt > 0 else 0

            fund_data = {
                'net_assets': net_assets_value if net_assets_value > 0 else (stock_amt / (stock_pct/100) if stock_pct > 0 else 0),
                'cash': cash_amt,
                'settlement': receivable_amt,
                'stock_value': stock_amt,
                'futures_nominal': futures_amt,
                'sub_payable': sub_payable,
                'red_payable': red_payable
            }

            # ä½¿ç”¨æ–°æ¨¡çµ„åˆ†æ
            alert_data = get_comprehensive_alert(fund_data)
            
            final_header = alert_data['Final_Alert']
            alert_sur = alert_data['Survival']
            alert_mom = alert_data['Momentum']
            alert_op = alert_data['Operation']
            
            total_exp = alert_data['Total_Exposure']
            sp = alert_data['SP_Ratio']
            flow_desc = alert_data['Flow_Desc']

            msg_trend = f"ğŸ“Š ã€è³‡é‡‘æ°´ä½ã€‘ ({target_date})\n"
            msg_trend += "-------------------------\n"
            msg_trend += f"ğŸ”” **{final_header}**\n"
            
            # é¡¯ç¤ºä¸‰å±¤ç´šè³‡è¨Š (é¿å…é‡è¤‡)
            if alert_sur:
                msg_trend += f"ğŸ’€ é¢¨éšª : {alert_sur}\n"
            
            # åªæœ‰ç•¶ header ä¸æ˜¯å‹•èƒ½è¨Šè™Ÿæ™‚æ‰é¡¯ç¤ºæµå‘
            if final_header != alert_mom:
                msg_trend += f"ğŸŒŠ æµå‘ : {alert_mom}\n"
            msg_trend += f"ğŸ® æ“ä½œ : {alert_op}\n"
            
            msg_trend += "-------------------------\n"
            msg_trend += f"ğŸ“ˆ è‚¡ç¥¨ : {stock_pct:>6.2f} %\n"
            msg_trend += f"ğŸ’µ ç¾é‡‘ : {cash_pct:>6.2f} %\n"
            msg_trend += f"âš–ï¸ æ‡‰æ”¶ä»˜ : {receivable_pct:>6.2f} %\n"
            msg_trend += f"ğŸ’³ ç”³è´–æ¬¾ : {raw_subs_pct:>6.2f} %\n"
            msg_trend += f"ğŸ² æœŸè²¨ : {futures_pct:>6.2f} %\n"
            msg_trend += f"â€¢ ç¸½æ›éšª : {total_exp:.2f} %\n"
            
            print(msg_trend)

            new_trend_data = {
                'æ—¥æœŸ': [target_date],
                'è‚¡ç¥¨': [stock_pct],
                'ç¾é‡‘': [cash_pct],
                'æœŸè²¨': [futures_pct],
                'æ‡‰æ”¶ä»˜': [receivable_pct],
                'ç”³è´–æ‡‰ä»˜æ¬¾': [raw_subs_pct],
                'æ·¨è³‡ç”¢': [fund_data['net_assets']],
                'ç¸½æ›éšª': [total_exp],
                # è¨ˆç®—å…¶ä»–æ¬„ä½ä»¥ç¶­æŒ CSV æ ¼å¼
                'è‚¡ç¥¨æ¬Šé‡': [stock_pct], # è¿‘ä¼¼å€¼
                'æœŸè²¨å½±éŸ¿': [futures_pct], # è¿‘ä¼¼å€¼
                'SPå€¼': [sp],
                'ECPå€¼': [cash_pct + receivable_pct],
                'æ“ä½œè­¦ç¤º': [final_header],
                'å‹•ä½œè¨Šè™Ÿ': [flow_desc], # ç”¨ Flow Desc å–ä»£èˆŠ Action
                'å§¿æ…‹è¨Šè™Ÿ': ["æ–°åˆ¶"],     # æ¨™è¨˜
                'å¤§ç›¤æ¼²è·Œ': [taiex_roi]
            }
            new_trend_df = pd.DataFrame(new_trend_data)
            status = save_data_with_overwrite(trend_filename, new_trend_df, date_col='æ—¥æœŸ')
            
            if status:
                print(f"âœ… è³‡é‡‘æ°´ä½å·²{status}")
                # [åœ–ç‰‡å ±å‘Šå–ä»£] send_telegram_message(msg_trend)

        except Exception as e: print(f"âš ï¸ è³‡é‡‘è™•ç†éŒ¯èª¤: {e}")

    # ---------------------------
    # ä»»å‹™ B: æŒè‚¡æ˜ç´° (å«è‚¡ç¥¨ä»£è™Ÿ)
    # ---------------------------
    if holdings_df is not None:
        try:
            col_name = [c for c in holdings_df.columns if "è‚¡ç¥¨åç¨±" in str(c)][0]
            col_shares = [c for c in holdings_df.columns if "è‚¡æ•¸" in str(c)][0]
            col_weight = [c for c in holdings_df.columns if "æŒè‚¡æ¬Šé‡" in str(c) or "æ¯”ä¾‹" in str(c)][0]
            col_id = [c for c in holdings_df.columns if "è‚¡ç¥¨ä»£è™Ÿ" in str(c)][0]
            
            holdings_df = holdings_df.dropna(subset=[col_name]).head(60)
            output_df = holdings_df[[col_id, col_name, col_shares, col_weight]].copy()
            output_df.columns = ['è‚¡ç¥¨ä»£è™Ÿ', 'è‚¡ç¥¨åç¨±', 'è‚¡æ•¸', 'æŒè‚¡æ¬Šé‡']
            output_df.insert(0, 'æ—¥æœŸ', target_date)
            
            status = save_data_with_overwrite(holdings_filename, output_df, date_col='æ—¥æœŸ')
            
            if status:
                print(f"ğŸ“‹ æŒè‚¡æ˜ç´°å·²{status}")
                
                history_df = pd.read_csv(holdings_filename).dropna(subset=['æ—¥æœŸ'])
                all_dates = sorted(history_df['æ—¥æœŸ'].unique())
                if len(all_dates) >= 2:
                    date_new, date_old = all_dates[-1], all_dates[-2]
                    df_new = history_df[history_df['æ—¥æœŸ'] == date_new]
                    df_old = history_df[history_df['æ—¥æœŸ'] == date_old]

                    # ğŸŒŸ å»ºç«‹ä»£è™Ÿå°ç…§è¡¨ (æ–°èˆŠè³‡æ–™åˆä½µæŸ¥è¡¨)
                    id_map = pd.concat([
                        df_new[['è‚¡ç¥¨åç¨±', 'è‚¡ç¥¨ä»£è™Ÿ']], 
                        df_old[['è‚¡ç¥¨åç¨±', 'è‚¡ç¥¨ä»£è™Ÿ']]
                    ]).drop_duplicates().set_index('è‚¡ç¥¨åç¨±')['è‚¡ç¥¨ä»£è™Ÿ'].to_dict()

                    def clean(x): 
                        try: return float(str(x).replace(',', ''))
                        except: return 0
                    d_new = dict(zip(df_new['è‚¡ç¥¨åç¨±'], df_new['è‚¡æ•¸'].apply(clean)))
                    d_old = dict(zip(df_old['è‚¡ç¥¨åç¨±'], df_old['è‚¡æ•¸'].apply(clean)))
                    
                    new_in = set(d_new.keys()) - set(d_old.keys())
                    msg1 = f"ğŸ†• ã€æ–°é€²æ¦œã€‘\n"
                    if new_in:
                        for n in new_in: 
                            sid = id_map.get(n, "")
                            # é¡¯ç¤ºæ ¼å¼: åç¨±(ä»£è™Ÿ)
                            msg1 += f"âœ¨ {n}({sid}) | {int(d_new[n]/1000):,} å¼µ\n"
                    else: msg1 += "ç„¡ã€‚\n"
                    
                    changes = []
                    # å»ºç«‹æ–°èˆŠæ¬Šé‡å°ç…§è¡¨
                    weight_map_new = {}
                    weight_map_old = {}
                    
                    for _, row in df_new.iterrows():
                        try:
                            wt = float(str(row['æŒè‚¡æ¬Šé‡']).replace('%', '').replace(',', ''))
                        except:
                            wt = 0
                        weight_map_new[row['è‚¡ç¥¨åç¨±']] = wt
                    
                    for _, row in df_old.iterrows():
                        try:
                            wt = float(str(row['æŒè‚¡æ¬Šé‡']).replace('%', '').replace(',', ''))
                        except:
                            wt = 0
                        weight_map_old[row['è‚¡ç¥¨åç¨±']] = wt
                    
                    # è®€å–æ”¶ç›¤åƒ¹å‡½æ•¸
                    def get_close_price(stock_code):
                        """å¾ history ç›®éŒ„è®€å–æ”¶ç›¤åƒ¹"""
                        try:
                            price_file = os.path.join(DATA_FOLDER, f'{stock_code}.csv')
                            if os.path.exists(price_file):
                                price_df = pd.read_csv(price_file)
                                if not price_df.empty and 'Close' in price_df.columns:
                                    return float(price_df.iloc[-1]['Close'])
                        except:
                            pass
                        return 0
                    
                    for n in set(d_new.keys()) | set(d_old.keys()):
                        diff = d_new.get(n, 0) - d_old.get(n, 0)
                        if diff != 0:
                            wt_new = weight_map_new.get(n, 0)
                            wt_old = weight_map_old.get(n, 0)
                            wt_change = wt_new - wt_old
                            # é‡‘é¡ = æ”¶ç›¤åƒ¹ Ã— è‚¡æ•¸å·®ç•°
                            stock_code = id_map.get(n, '')
                            close_price = get_close_price(stock_code)
                            amount = abs(close_price * diff)
                            changes.append({
                                'name': n,
                                'code': stock_code,
                                'diff': diff,
                                'weight': wt_new,
                                'weight_change': wt_change,
                                'amount': amount
                            })
                    
                    # æŒ‰æ¬Šé‡è®ŠåŒ–æ’åºï¼ˆçµ•å°å€¼ï¼‰
                    changes.sort(key=lambda x: abs(x['weight_change']), reverse=True)
                    
                    # åˆ†é›¢å¢æŒå’Œæ¸›æŒ
                    increases = [c for c in changes if c['diff'] > 0]
                    decreases = [c for c in changes if c['diff'] < 0]
                    
                    # è¨ˆç®—é€£çºŒå¤©æ•¸ (ç”¨ history_map)
                    def get_streak(name, direction='buy'):
                        """è¨ˆç®—é€£çºŒè²·é€²/è³£å‡ºå¤©æ•¸"""
                        if len(all_dates) < 3:
                            return 0
                        streak = 0
                        sorted_d = sorted(all_dates)
                        
                        # å»ºç«‹è©²è‚¡ç¥¨çš„æ­·å²è³‡æ–™
                        stock_history = {}
                        for _, row in history_df[history_df['è‚¡ç¥¨åç¨±'] == name].iterrows():
                            try:
                                sh = float(str(row['è‚¡æ•¸']).replace(',', ''))
                            except:
                                sh = 0
                            stock_history[row['æ—¥æœŸ']] = sh
                        
                        check_val = stock_history.get(sorted_d[-1], 0)
                        for i in range(len(sorted_d)-2, -1, -1):
                            prev_val = stock_history.get(sorted_d[i], 0)
                            if direction == 'buy':
                                if check_val > prev_val and prev_val > 0:
                                    streak += 1
                                    check_val = prev_val
                                else:
                                    break
                            else:  # sell
                                if check_val < prev_val:
                                    streak += 1
                                    check_val = prev_val
                                else:
                                    break
                        return streak + 1 if streak > 0 else 0
                    
                    msg2 = "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    msg2 += "ğŸ”¥ã€è®Šå‹•æ’è¡Œã€‘\n"
                    msg2 += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                    
                    # å¢æŒ TOP 5
                    msg2 += "ğŸ“ˆ å¢æŒ TOP 5\n"
                    for item in increases[:5]:
                        n, sid = item['name'], item['code']
                        diff, wt = item['diff'], item['weight']
                        streak = get_streak(n, 'buy')
                        streak_txt = f" | é€£çºŒåŠ ç¢¼ {streak} å¤© ğŸ”¥" if streak >= 2 else ""
                        large_txt = " ğŸ”¥" if abs(diff) > 3000000 else ""  # 3000å¼µ
                        msg2 += f"ğŸ”´ {n} ({sid}): +{int(diff/1000):,} å¼µ | æ¬Šé‡ {wt:.2f}%{streak_txt}{large_txt}\n"
                    
                    msg2 += "\nğŸ“‰ æ¸›æŒ TOP 3\n"
                    for item in decreases[:3]:
                        n, sid = item['name'], item['code']
                        diff, wt = item['diff'], item['weight']
                        streak = get_streak(n, 'sell')
                        streak_txt = f" | é€£çºŒæ¸›ç¢¼ {streak} å¤© âš ï¸" if streak >= 3 else ""
                        msg2 += f"ğŸŸ¢ {n} ({sid}): {int(diff/1000):,} å¼µ | æ¬Šé‡ {wt:.2f}%{streak_txt}\n"

                    # [åœ–ç‰‡å ±å‘Šå–ä»£] send_telegram_message(msg1)
                    time.sleep(1)
                    # [åœ–ç‰‡å ±å‘Šå–ä»£] send_telegram_message(msg2)
                else: print("âš ï¸ ç„¡æ³•æ¯”å° (é¦–ç­†è³‡æ–™)ã€‚")

                # ğŸŒŸ [æ–°å¢åŠŸèƒ½] é€£çºŒè²·é€²åµæ¸¬ (Streak Detection)
                if len(all_dates) >= 3:
                    try:
                        print(f"ğŸ” å•Ÿå‹•é€£çºŒè²·é€²åµæ¸¬ (æ­·å²è³‡æ–™å…± {len(all_dates)} å¤©)...")
                        
                        # é‡å»ºå¿«é€ŸæŸ¥è©¢è¡¨ {name: {date: shares}}
                        history_map = {} 
                        # åªå–æœ€è¿‘ 30 å¤©è³‡æ–™ä»¥å…éæ…¢ (é›–ç„¶æ‡‰è©²ä¸æœƒ)
                        recent_dates = all_dates[-30:]
                        # è½‰æˆ List ä»¥ä¾¿ Index å›æº¯ (all_dates å·²æ˜¯ sort ver)
                        sorted_dates = sorted(list(recent_dates)) # æ˜ç¢ºæ’åº (é›–ç„¶ unique å¾Œæ‡‰è©²å·²æ’)
                        
                        # ç¯©é¸é€™äº›æ—¥æœŸçš„ rows
                        sub_df = history_df[history_df['æ—¥æœŸ'].isin(sorted_dates)]
                        
                        for _, row in sub_df.iterrows():
                            nm = row['è‚¡ç¥¨åç¨±']
                            dt = row['æ—¥æœŸ']
                            sh = 0
                            try: sh = float(str(row['è‚¡æ•¸']).replace(',', ''))
                            except: pass
                            
                            if nm not in history_map: history_map[nm] = {}
                            history_map[nm][dt] = sh
                            
                        # é–‹å§‹åˆ†æ (é‡å°ä»Šæ—¥æœ‰æŒè‚¡çš„)
                        streak_list = []
                        latest_date = sorted_dates[-1]
                        
                        for name in d_new.keys(): # d_new æ˜¯ä»Šå¤©æœ‰æŒè‚¡çš„
                            shares_now = d_new.get(name, 0)
                            
                            current_streak = 0
                            # å›æº¯æª¢æŸ¥
                            # dates: [T-N, ..., T-2, T-1, T]
                            # index: -1 is T, -2 is T-1
                            
                            # è‡³å°‘è¦æœ‰ T-1 (index -2) æ‰èƒ½ç®— streak=1? 
                            # ä¸ï¼Œå®šç¾©ï¼š
                            # T > T-1 (é€£è²· 1 å¤©? ä¸ï¼Œé€™å«è²·è¶… 1 å¤©)
                            # T > T-1 > T-2 (é€£è²· 2 å¤©? é‚„æ˜¯ 3 å¤©?)
                            # é¡Œç›®ï¼šé€£çºŒä¸‰å¤©è²·å…¥ => T, T-1, T-2 å‘ˆç¾éå¢
                            # Streak å®šç¾©ç‚ºã€Œé€£çºŒå¢é•·æ¬¡æ•¸ã€ + 1 ? æˆ–è€…ã€Œé€£çºŒå¢é•·çš„å¤©æ•¸ã€
                            # è‹¥ T > T-1ï¼Œstreak=2 (åŒ…å«ä»Šå¤©èˆ‡æ˜¨å¤©)
                            # è‹¥ T > T-1 > T-2ï¼Œstreak=3
                            
                            check_val = shares_now
                            streak = 0 # åˆå§‹ç‚º 0ï¼Œè¨ˆç®—ã€Œå¢é•·æ¬¡æ•¸ã€
                            
                            for i in range(len(sorted_dates)-2, -1, -1):
                                d_prev = sorted_dates[i]
                                shares_prev = history_map.get(name, {}).get(d_prev, 0)
                                
                                # åš´æ ¼éå¢
                                if check_val > shares_prev and shares_prev > 0:
                                    streak += 1
                                    check_val = shares_prev
                                else:
                                    break
                            
                            # streak ç¾åœ¨ä»£è¡¨ã€Œé€£çºŒå¢é•·æ¬¡æ•¸ã€
                            # æœ€çµ‚é¡¯ç¤ºæ‡‰è©²æ˜¯ streak + 1ï¼ˆåŒ…å«ä»Šå¤©ï¼‰
                            # ä¾‹å¦‚ï¼šT > T-1 > T-2 => streak=2ï¼Œå¯¦éš›é€£è²· 3 å¤©
                            actual_days = streak + 1
                            
                            if actual_days >= 3:
                                # è¨ˆç®—æœ¬æ—¥å¢åŠ é‡ (for display)
                                prev_day_shares = history_map.get(name, {}).get(sorted_dates[-2], 0)
                                diff = shares_now - prev_day_shares
                                streak_list.append({
                                    'name': name,
                                    'code': id_map.get(name, ""),
                                    'streak': actual_days,  # ä½¿ç”¨å¯¦éš›å¤©æ•¸
                                    'diff': diff
                                })
                        
                        if streak_list:
                            # æ’åº: å¤©æ•¸å¤š > å¢åŠ å¼µæ•¸å¤š
                            streak_list.sort(key=lambda x: (x['streak'], x['diff']), reverse=True)
                            
                            msg3 = "ğŸš€ ã€é€£çºŒåŠ ç¢¼è­¦ç¤ºã€‘\n"
                            for item in streak_list:
                                msg3 += f"ğŸš€ {item['name']}({item['code']}) | +{int(item['diff']/1000):,}å¼µ (é€£è²· {item['streak']} å¤©)\n"
                                
                            print("âœ… ç™¼é€é€£çºŒè²·é€²é€šçŸ¥...")
                            # [åœ–ç‰‡å ±å‘Šå–ä»£] send_telegram_message(msg3)
                        else:
                            print("â„¹ï¸ ç„¡é€£çºŒ 3 å¤©è²·é€²æ¨™çš„ã€‚")

                    except Exception as e:
                        print(f"âš ï¸ é€£çºŒè²·é€²åµæ¸¬éŒ¯èª¤: {e}")

                # ==========================================
                # ğŸª ä»»å‹™ C: æ¦‚å¿µè‚¡é…ç½®åˆ†æ
                # ==========================================
                try:
                    print("ğŸª å•Ÿå‹•æ¦‚å¿µè‚¡é…ç½®åˆ†æ...")
                    
                    # è¨ˆç®—ä»Šæ—¥å„æ—ç¾¤æ¬Šé‡
                    group_weights_today = calculate_group_weights(df_new, code_col='è‚¡ç¥¨ä»£è™Ÿ', weight_col='æŒè‚¡æ¬Šé‡')
                    
                    # è¼‰å…¥æ˜¨æ—¥æ—ç¾¤æ¬Šé‡ (å¾æ­·å²æª”)
                    group_weights_yesterday = {}
                    if os.path.exists(concept_filename):
                        try:
                            concept_df = pd.read_csv(concept_filename)
                            yesterday_concept = concept_df[concept_df['æ—¥æœŸ'] == date_old]
                            for _, row in yesterday_concept.iterrows():
                                group_weights_yesterday[row['æ—ç¾¤']] = row['æ¬Šé‡']
                        except Exception as e:
                            print(f"âš ï¸ è®€å–æ—ç¾¤æ­·å²å¤±æ•—: {e}")
                    
                    # è¨ˆç®—è®ŠåŒ–é‡
                    group_changes = {}
                    all_groups = set(group_weights_today.keys()) | set(group_weights_yesterday.keys())
                    for g in all_groups:
                        today_w = group_weights_today.get(g, 0)
                        yesterday_w = group_weights_yesterday.get(g, 0)
                        change = today_w - yesterday_w
                        group_changes[g] = (today_w, change)
                    
                    # å„²å­˜ä»Šæ—¥æ—ç¾¤æ¬Šé‡
                    concept_records = []
                    for g, (w, c) in group_changes.items():
                        concept_records.append({
                            'æ—¥æœŸ': target_date,
                            'æ—ç¾¤': g,
                            'æ¬Šé‡': round(w, 2),
                            'è®ŠåŒ–': round(c, 2)
                        })
                    if concept_records:
                        new_concept_df = pd.DataFrame(concept_records)
                        save_data_with_overwrite(concept_filename, new_concept_df, date_col='æ—¥æœŸ')
                        print(f"âœ… æ—ç¾¤æ¬Šé‡å·²å„²å­˜")
                    
                    # è¨ˆç®—å„æ—ç¾¤å…§çš„å€‹è‚¡è®ŠåŒ–
                    group_stock_changes = calculate_group_stock_changes(
                        df_new, df_old,
                        code_col='è‚¡ç¥¨ä»£è™Ÿ', name_col='è‚¡ç¥¨åç¨±', shares_col='è‚¡æ•¸'
                    )
                    
                    # æ’åºå– TOP 3 å¢æŒå’Œ TOP 3 æ¸›æŒ
                    sorted_groups = sorted(group_changes.items(), key=lambda x: x[1][1], reverse=True)
                    top_increases = [(g, w, c) for g, (w, c) in sorted_groups if c > 0][:3]
                    top_decreases = [(g, w, c) for g, (w, c) in sorted_groups if c < 0][-3:][::-1]  # å–æœ€å¾Œ3å€‹åè½‰
                    top_decreases = sorted([(g, w, c) for g, (w, c) in sorted_groups if c < 0], key=lambda x: x[2])[:3]
                    
                    msg4 = "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    msg4 += "ğŸªã€æ¦‚å¿µè‚¡é…ç½®ã€‘\n"
                    msg4 += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                    
                    # å¢æŒ TOP 3
                    msg4 += "ğŸ“ˆ å¢æŒ TOP 3\n"
                    for g, w, c in top_increases:
                        arrow = "â†‘" if c > 0.1 else "â†’"
                        msg4 += f"ğŸ”´ {g}ï¼š{w:.1f}% ({arrow} {abs(c):.1f}%)\n"
                        # åˆ—å‡ºè©²æ—ç¾¤ä¸»è¦åŠ ç¢¼å€‹è‚¡ (æœ€å¤š3æª”)
                        if g in group_stock_changes:
                            top_stocks = [s for s in group_stock_changes[g] if s[2] > 0][:3]
                            if top_stocks:
                                stock_txt = "ã€".join([f"{s[0]} +{int(s[2]/1000):,}å¼µ" for s in top_stocks])
                                msg4 += f"   â€¢ ä¸»è¦åŠ ç¢¼ï¼š{stock_txt}\n"
                        msg4 += "\n"
                    
                    # æ¸›æŒ TOP 3
                    msg4 += "ğŸ“‰ æ¸›æŒ TOP 3\n"
                    for g, w, c in top_decreases:
                        arrow = "â†“" if c < -0.1 else "â†’"
                        msg4 += f"ğŸŸ¢ {g}ï¼š{w:.1f}% ({arrow} {abs(c):.1f}%)\n"
                        # åˆ—å‡ºè©²æ—ç¾¤ä¸»è¦æ¸›ç¢¼å€‹è‚¡ (æœ€å¤š3æª”)
                        if g in group_stock_changes:
                            top_stocks = [s for s in group_stock_changes[g] if s[2] < 0][:3]
                            if top_stocks:
                                stock_txt = "ã€".join([f"{s[0]} {int(s[2]/1000):,}å¼µ" for s in top_stocks])
                                msg4 += f"   â€¢ ä¸»è¦æ¸›ç¢¼ï¼š{stock_txt}\n"
                        msg4 += "\n"
                    
                    if top_increases or top_decreases:
                        # [åœ–ç‰‡å ±å‘Šå–ä»£] send_telegram_message(msg4)
                        print("âœ… æ¦‚å¿µè‚¡é…ç½®å·²æ•´åˆåˆ°åœ–ç‰‡å ±å‘Š")
                    
                    # ==========================================
                    # ğŸš¨ ä»»å‹™ D: ç•°å¸¸åµæ¸¬è­¦ç¤º
                    # ==========================================
                    alerts = []
                    
                    # 1. æ—ç¾¤å–®æ—¥è®Šå‹• > 1% â†’ é¡Œæç†±åº¦ç•°å¸¸
                    for g, (w, c) in group_changes.items():
                        if c > 1.0:
                            # æ‰¾å‡ºæœ€å¤§æ¨æ‰‹
                            if g in group_stock_changes:
                                top_stock = group_stock_changes[g][0] if group_stock_changes[g] else None
                                if top_stock:
                                    alerts.append(f"ğŸ”¥ é¡Œæç†±åº¦ç•°å¸¸\nâš ï¸ {g}æ—ç¾¤å–®æ—¥æš´å¢ {c:.1f}%\n   â†’ {top_stock[0]} +{int(top_stock[2]/1000):,}å¼µ ç‚ºæœ€å¤§æ¨æ‰‹")
                        elif c < -1.0:
                            alerts.append(f"â„ï¸ é¡Œæé™æº«è­¦è¨Š\nâš ï¸ {g}æ—ç¾¤å–®æ—¥æ¸›å°‘ {abs(c):.1f}%")
                    
                    # 2. ç¾é‡‘æ°´ä½ > 6% â†’ é˜²ç¦¦è¨Šè™Ÿ
                    if cash_pct > 6.0:
                        alerts.append(f"ğŸ›¡ï¸ é˜²ç¦¦è¨Šè™Ÿ\nâš ï¸ ç¾é‡‘æ°´ä½åé«˜ ({cash_pct:.1f}%)")
                    
                    # 3. ç”³è´–æ¬¾é€£çºŒç‚ºè² æª¢æ¸¬ (éœ€è¦æ­·å²è³‡æ–™)
                    if raw_subs_pct < 0:
                        alerts.append(f"âš ï¸ è³‡é‡‘æµå‡ºè¨Šè™Ÿ\n   ç”³è´–æ¬¾ç‚ºè²  ({raw_subs_pct:.2f}%)ï¼Œè´–å› > ç”³è³¼")
                    
                    if alerts:
                        # [åœ–ç‰‡å ±å‘Šå–ä»£] ç•°å¸¸è­¦ç¤ºå·²æ•´åˆåˆ°åœ–ç‰‡å ±å‘Š
                        print("â„¹ï¸ ç•°å¸¸è­¦ç¤ºå·²æ•´åˆåˆ°åœ–ç‰‡å ±å‘Š")
                    else:
                        print("â„¹ï¸ ç„¡ç•°å¸¸è­¦ç¤º")
                    
                except Exception as e:
                    print(f"âš ï¸ æ¦‚å¿µè‚¡é…ç½®åˆ†æéŒ¯èª¤: {e}")

        except Exception as e:
            print(f"âš ï¸ æŒè‚¡æ˜ç´°è™•ç†éŒ¯èª¤: {e}")

    # ==========================================
    # ğŸ–¼ï¸ ä»»å‹™ E: ç”Ÿæˆåœ–ç‰‡å ±å‘Šä¸¦ç™¼é€
    # ==========================================
    try:
        print("ğŸ–¼ï¸ æ­£åœ¨ç”Ÿæˆåœ–ç‰‡å ±å‘Š...")
        
        # é è¨­è®Šæ•¸åˆå§‹åŒ–ï¼ˆé˜²æ­¢å‰é¢å€å¡Šå› ç•°å¸¸è·³éå°è‡´è®Šæ•¸æœªå®šç¾©ï¼‰
        if 'increases' not in dir(): increases = []
        if 'decreases' not in dir(): decreases = []
        if 'streak_list' not in dir(): streak_list = []
        if 'new_in' not in dir(): new_in = set()
        if 'd_new' not in dir(): d_new = {}
        if 'id_map' not in dir(): id_map = {}
        if 'top_increases' not in dir(): top_increases = []
        if 'top_decreases' not in dir(): top_decreases = []
        if 'group_stock_changes' not in dir(): group_stock_changes = {}
        
        # ç”Ÿæˆ AI ç¸½çµ
        ai_summary = ""
        if 'increases' in dir() and increases:
            buy_names = [x['name'] for x in increases[:2]]
            ai_summary = f"ç¶“ç†äººä»Šæ—¥é‡é»åŠ ç¢¼{'ã€'.join(buy_names)}"
            if 'total_exp' in dir():
                if total_exp > 95:
                    ai_summary += "ï¼Œç¸½æ›éšªç¶­æŒé«˜æª”ï¼Œæ…‹åº¦ç©æ¥µã€‚"
                elif total_exp < 85:
                    ai_summary += "ï¼Œç¸½æ›éšªåä½ï¼Œæ“ä½œåä¿å®ˆã€‚"
                else:
                    ai_summary += "ã€‚"
        elif 'decreases' in dir() and decreases:
            sell_names = [x['name'] for x in decreases[:2]]
            ai_summary = f"ç¶“ç†äººä»Šæ—¥ä¸»è¦æ¸›ç¢¼{'ã€'.join(sell_names)}ï¼Œæ“ä½œåå‘èª¿ç¯€ã€‚"
        else:
            ai_summary = "ç¶“ç†äººä»Šæ—¥æ“ä½œè®Šå‹•ä¸å¤§ï¼Œå¤šç©ºäº’è¦‹ã€‚"
        
        # æ”¶é›†å ±å‘Šè³‡æ–™
        report_data = {
            'date': target_date,
            'water_level': {
                'final_alert': final_header if 'final_header' in dir() else 'è³‡é‡‘æµå‘æ­£å¸¸',
                'operation': alert_op if 'alert_op' in dir() else '',
                'stock_pct': stock_pct if 'stock_pct' in dir() else 0,
                'cash_pct': cash_pct if 'cash_pct' in dir() else 0,
                'receivable_pct': receivable_pct if 'receivable_pct' in dir() else 0,
                'subs_pct': raw_subs_pct if 'raw_subs_pct' in dir() else 0,
                'futures_pct': futures_pct if 'futures_pct' in dir() else 0,
                'total_exposure': total_exp if 'total_exp' in dir() else 0
            },
            'new_entries': [],
            'changes': {
                'increases': [],
                'decreases': []
            },
            'streak_alerts': [],
            'concept': {
                'increases': [],
                'decreases': [],
                'group_stock_changes': {}
            },
            'ai_summary': ai_summary
        }
        
        # å¡«å…¥æ–°é€²æ¦œ (å¦‚æœæœ‰)
        if 'new_in' in dir() and new_in and 'd_new' in dir() and 'id_map' in dir():
            report_data['new_entries'] = [
                {'name': n, 'code': id_map.get(n, ''), 'shares': d_new.get(n, 0)}
                for n in new_in
            ]
        
        # å¡«å…¥è®Šå‹•è³‡æ–™ (å¦‚æœæœ‰) - ä»¥æ¬Šé‡è®ŠåŒ–æ’åº
        if 'increases' in dir() and increases:
            report_data['changes']['increases'] = increases[:5]
        if 'decreases' in dir() and decreases:
            report_data['changes']['decreases'] = decreases[:3]
        
        # å¡«å…¥é€£çºŒåŠ ç¢¼ (å¦‚æœæœ‰)
        if 'streak_list' in dir() and streak_list:
            report_data['streak_alerts'] = streak_list
        
        # å¡«å…¥æ¦‚å¿µè‚¡ (å¦‚æœæœ‰)
        if 'top_increases' in dir() and top_increases:
            report_data['concept']['increases'] = top_increases
        if 'top_decreases' in dir() and top_decreases:
            report_data['concept']['decreases'] = top_decreases
        if 'group_stock_changes' in dir() and group_stock_changes:
            report_data['concept']['group_stock_changes'] = group_stock_changes
        
        # ç”Ÿæˆåœ–ç‰‡
        image_path = generate_fund_report_image(report_data)
        
        # ç™¼é€åœ–ç‰‡
        send_telegram_photo(image_path, f"00981A ç¶“ç†äººæ—¥å ± - {target_date}")
        
        # ç™¼é€å¾Œåˆªé™¤åœ–ç‰‡ (ç¯€çœç©ºé–“)
        try:
            os.remove(image_path)
            print(f"ğŸ—‘ï¸ å·²åˆªé™¤æš«å­˜åœ–ç‰‡: {image_path}")
        except:
            pass
        
    except Exception as e:
        print(f"âš ï¸ åœ–ç‰‡å ±å‘Šç”ŸæˆéŒ¯èª¤: {e}")
        # Fallback: ç™¼é€åŸæœ¬çš„æ–‡å­—è¨Šæ¯
        if 'msg_trend' in dir():
            send_telegram_message(msg_trend)

except Exception as e: print(f"âŒ éŒ¯èª¤: {e}")
finally:
    try: driver.quit()
    except: pass