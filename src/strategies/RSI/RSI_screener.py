import os
import sys
import pandas as pd
import numpy as np
import requests
from datetime import datetime
from dotenv import load_dotenv

# ============================================================
# RSI èƒŒé›¢ç¯©é¸ç³»çµ± (RSI Divergence Screener)
# v3.1 - TradingView Pivot + ISO å‘¨ç·šç‰ˆ
# ============================================================

# --- Load Environment Variables ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_dir)))
env_path = os.path.join(project_root, ".env")
load_dotenv(env_path)

# åŠ å…¥ src è·¯å¾‘ä»¥ä¾¿ import å…±ç”¨æ¨¡çµ„
sys.path.insert(0, os.path.join(project_root, "src"))
from utils.trading_day_utils import is_trading_day

# --- Configuration ---
CACHE_FILE = os.path.join(project_root, "src", "cache", "market_matrix.pkl")
NAME_MAP_FILE = os.path.join(project_root, "src", "data_core", "market_meta", "moneydj_industries.csv")

# --- Parameters ---
LIQUIDITY_THRESHOLD = 50_000_000  # 5000è¬ (Filter 1)
RSI_PERIOD = 14                    # RSI é€±æœŸï¼ˆå°é½Š TradingViewï¼‰
PIVOT_LB_LEFT = 5                  # Pivot Lookback Left
PIVOT_LB_RIGHT = 5                 # Pivot Lookback Right
RANGE_UPPER = 60                   # Max lookback rangeï¼ˆå‰ä¸€å€‹ pivot æœ€é è·é›¢ï¼‰
RANGE_LOWER = 5                    # Min lookback rangeï¼ˆå‰ä¸€å€‹ pivot æœ€è¿‘è·é›¢ï¼‰
ENABLE_WEEKLY = True               # æ˜¯å¦å•Ÿç”¨å‘¨ç·šç¯©é¸
DEBUG_MODE = "--debug" in sys.argv # Debug æ¨¡å¼


def load_data():
    """è¼‰å…¥å¸‚å ´çŸ©é™£å¿«å–"""
    if not os.path.exists(CACHE_FILE):
        print("âŒ Cache not found! Please run 'optimize_matrix.py' first.")
        return None
    
    print("âœ… è¼‰å…¥å¸‚å ´çŸ©é™£ (Market Matrix)...")
    try:
        import pickle
        with open(CACHE_FILE, 'rb') as f:
            data = pickle.load(f)
        return data
    except Exception as e:
        print(f"âŒ å¿«å–æå£: {e}")
        return None


def load_name_map():
    """è¼‰å…¥è‚¡ç¥¨åç¨±å°ç…§è¡¨"""
    name_map = {}
    try:
        if os.path.exists(NAME_MAP_FILE):
            with open(NAME_MAP_FILE, 'r', encoding='utf-8-sig', errors='ignore') as f:
                for line in f:
                    parts = line.strip().split(',')
                    if len(parts) >= 2:
                        name_map[parts[0].strip()] = parts[1].strip()
    except Exception:
        pass
    return name_map


# is_trading_day å·²ç§»è‡³ utils.trading_day_utilsï¼ˆé€é FinMind API åˆ¤æ–·ï¼‰


# ============================================================
# ğŸ”§ æ ¸å¿ƒè¨ˆç®—æ¨¡çµ„ï¼ˆå°é½Š TradingViewï¼‰
# ============================================================

def calculate_rsi(price_series, period=14):
    """
    Wilder's RSIï¼ˆèˆ‡ TradingView ta.rsi ç›¸åŒï¼‰
    
    é‚è¼¯ï¼š
    - åˆå§‹åŒ–ï¼šå‰ period æ ¹ç”¨ SMA
    - ä¹‹å¾Œï¼šWilder å¹³æ»‘ (alpha = 1/period)
    - RSI = 100 * avgUp / (avgUp + avgDown)
    """
    delta = price_series.diff()
    up = delta.clip(lower=0)
    down = (-delta).clip(lower=0)
    
    sum_up = np.zeros(len(price_series))
    sum_down = np.zeros(len(price_series))
    rsi = np.full(len(price_series), np.nan)
    
    first_valid = period
    
    if first_valid < len(price_series):
        sum_up[first_valid] = up.iloc[1:first_valid+1].mean()
        sum_down[first_valid] = down.iloc[1:first_valid+1].mean()
    
    alpha = 1.0 / period
    for i in range(first_valid + 1, len(price_series)):
        sum_up[i] = sum_up[i-1] + (up.iloc[i] - sum_up[i-1]) * alpha
        sum_down[i] = sum_down[i-1] + (down.iloc[i] - sum_down[i-1]) * alpha
    
    for i in range(first_valid, len(price_series)):
        denom = sum_up[i] + sum_down[i]
        if denom == 0:
            rsi[i] = 0
        else:
            rsi[i] = 100 * sum_up[i] / denom
    
    return pd.Series(rsi, index=price_series.index)


def find_pivot_lows(series, lbL=5, lbR=5):
    """
    ç¿»è­¯ TradingView çš„ ta.pivotlow
    
    åœ¨ä½ç½® i è™•ï¼Œå¦‚æœ series[i] æ˜¯ [i-lbL, i+lbR] ç¯„åœå…§çš„æœ€å°å€¼ï¼Œ
    å‰‡ i æ˜¯ pivot lowã€‚
    
    Returns:
        list of int: pivot low çš„ä½ç½®ç´¢å¼•
    """
    vals = series.values
    pivots = []
    
    for i in range(lbL, len(vals) - lbR):
        val = vals[i]
        if np.isnan(val):
            continue
        
        is_pivot = True
        for j in range(i - lbL, i):
            if np.isnan(vals[j]) or vals[j] < val:
                is_pivot = False
                break
        
        if not is_pivot:
            continue
        
        for j in range(i + 1, i + lbR + 1):
            if np.isnan(vals[j]) or vals[j] < val:
                is_pivot = False
                break
        
        if is_pivot:
            pivots.append(i)
    
    return pivots


def find_pivot_highs(series, lbL=5, lbR=5):
    """
    ç¿»è­¯ TradingView çš„ ta.pivothigh
    
    åœ¨ä½ç½® i è™•ï¼Œå¦‚æœ series[i] æ˜¯ [i-lbL, i+lbR] ç¯„åœå…§çš„æœ€å¤§å€¼ï¼Œ
    å‰‡ i æ˜¯ pivot highã€‚
    
    Returns:
        list of int: pivot high çš„ä½ç½®ç´¢å¼•
    """
    vals = series.values
    pivots = []
    
    for i in range(lbL, len(vals) - lbR):
        val = vals[i]
        if np.isnan(val):
            continue
        
        is_pivot = True
        for j in range(i - lbL, i):
            if np.isnan(vals[j]) or vals[j] > val:
                is_pivot = False
                break
        
        if not is_pivot:
            continue
        
        for j in range(i + 1, i + lbR + 1):
            if np.isnan(vals[j]) or vals[j] > val:
                is_pivot = False
                break
        
        if is_pivot:
            pivots.append(i)
    
    return pivots


def detect_divergences(rsi_series, price_high, price_low,
                       lbL=5, lbR=5, range_lower=5, range_upper=60):
    """
    ç¿»è­¯ TradingView RSI Divergence Indicator çš„èƒŒé›¢åµæ¸¬é‚è¼¯
    
    Regular Bullish:  RSI Higher Low + Price Lower Low   (åº•éƒ¨åè½‰)
    Hidden Bullish:   RSI Lower Low  + Price Higher Low  (è¶¨å‹¢å»¶çºŒ)
    Regular Bearish:  RSI Lower High + Price Higher High  (é ‚éƒ¨åè½‰)
    Hidden Bearish:   RSI Higher High + Price Lower High  (è¶¨å‹¢å»¶çºŒ)
    
    Args:
        rsi_series: RSI pd.Series
        price_high: æœ€é«˜åƒ¹ pd.Seriesï¼ˆç”¨æ–¼ bearish æ¯”è¼ƒï¼‰
        price_low:  æœ€ä½åƒ¹ pd.Seriesï¼ˆç”¨æ–¼ bullish æ¯”è¼ƒï¼‰
        lbL, lbR:   Pivot lookback åƒæ•¸
        range_lower, range_upper: å‰ä¸€å€‹ pivot çš„æœ‰æ•ˆè·é›¢ç¯„åœ
    
    Returns:
        list of dict: æ¯å€‹èƒŒé›¢è¨Šè™Ÿ
    """
    rsi_vals = rsi_series.values
    high_vals = price_high.values
    low_vals = price_low.values
    
    # æ‰¾ RSI çš„ pivot points
    pivot_lows = find_pivot_lows(rsi_series, lbL, lbR)
    pivot_highs = find_pivot_highs(rsi_series, lbL, lbR)
    
    signals = []
    
    # --- Bullish divergences (åœ¨ pivot low è™•æª¢æŸ¥) ---
    for i, pl_idx in enumerate(pivot_lows):
        prev_pl_idx = None
        for j in range(i - 1, -1, -1):
            bars_diff = pl_idx - pivot_lows[j]
            if range_lower <= bars_diff <= range_upper:
                prev_pl_idx = pivot_lows[j]
                break
        
        if prev_pl_idx is None:
            continue
        
        rsi_curr = rsi_vals[pl_idx]
        rsi_prev = rsi_vals[prev_pl_idx]
        price_curr = low_vals[pl_idx]
        price_prev = low_vals[prev_pl_idx]
        
        confirm_bar = pl_idx + lbR
        if confirm_bar >= len(rsi_vals):
            continue
        
        # Regular Bullish: RSI Higher Low + Price Lower Low
        if rsi_curr > rsi_prev and price_curr < price_prev:
            signals.append({
                'bar': pl_idx,
                'confirm_bar': confirm_bar,
                'type': 'bull',
                'rsi_curr': rsi_curr,
                'rsi_prev': rsi_prev,
                'price_curr': price_curr,
                'price_prev': price_prev,
            })
        
        # Hidden Bullish: RSI Lower Low + Price Higher Low
        if rsi_curr < rsi_prev and price_curr > price_prev:
            signals.append({
                'bar': pl_idx,
                'confirm_bar': confirm_bar,
                'type': 'hidden_bull',
                'rsi_curr': rsi_curr,
                'rsi_prev': rsi_prev,
                'price_curr': price_curr,
                'price_prev': price_prev,
            })
    
    # --- Bearish divergences (åœ¨ pivot high è™•æª¢æŸ¥) ---
    for i, ph_idx in enumerate(pivot_highs):
        prev_ph_idx = None
        for j in range(i - 1, -1, -1):
            bars_diff = ph_idx - pivot_highs[j]
            if range_lower <= bars_diff <= range_upper:
                prev_ph_idx = pivot_highs[j]
                break
        
        if prev_ph_idx is None:
            continue
        
        rsi_curr = rsi_vals[ph_idx]
        rsi_prev = rsi_vals[prev_ph_idx]
        price_curr = high_vals[ph_idx]
        price_prev = high_vals[prev_ph_idx]
        
        confirm_bar = ph_idx + lbR
        if confirm_bar >= len(rsi_vals):
            continue
        
        # Regular Bearish: RSI Lower High + Price Higher High
        if rsi_curr < rsi_prev and price_curr > price_prev:
            signals.append({
                'bar': ph_idx,
                'confirm_bar': confirm_bar,
                'type': 'bear',
                'rsi_curr': rsi_curr,
                'rsi_prev': rsi_prev,
                'price_curr': price_curr,
                'price_prev': price_prev,
            })
        
        # Hidden Bearish: RSI Higher High + Price Lower High
        if rsi_curr > rsi_prev and price_curr < price_prev:
            signals.append({
                'bar': ph_idx,
                'confirm_bar': confirm_bar,
                'type': 'hidden_bear',
                'rsi_curr': rsi_curr,
                'rsi_prev': rsi_prev,
                'price_curr': price_curr,
                'price_prev': price_prev,
            })
    
    signals.sort(key=lambda x: x['confirm_bar'])
    return signals


def check_divergences_for_stock(price_close, price_high, price_low,
                                rsi_period=14, max_bars_ago=10):
    """
    å°å–®ä¸€è‚¡ç¥¨åµæ¸¬æœ€è¿‘çš„ RSI èƒŒé›¢è¨Šè™Ÿ
    """
    if len(price_close) < rsi_period + PIVOT_LB_LEFT + PIVOT_LB_RIGHT + RANGE_LOWER:
        return []
    
    rsi = calculate_rsi(price_close, period=rsi_period)
    
    all_signals = detect_divergences(
        rsi, price_high, price_low,
        lbL=PIVOT_LB_LEFT, lbR=PIVOT_LB_RIGHT,
        range_lower=RANGE_LOWER, range_upper=RANGE_UPPER
    )
    
    if not all_signals:
        return []
    
    last_bar = len(price_close) - 1
    recent_signals = []
    
    for sig in all_signals:
        bars_ago = last_bar - sig['confirm_bar']
        if 0 <= bars_ago <= max_bars_ago:
            sig['date_pivot'] = price_close.index[sig['bar']]
            sig['date_confirm'] = price_close.index[sig['confirm_bar']]
            sig['bars_ago'] = bars_ago
            recent_signals.append(sig)
    
    return recent_signals


# ============================================================
# ğŸ“… å‘¨ç·šèšåˆï¼ˆISO å‘¨æ¬¡åˆ†çµ„ï¼‰
# ============================================================

def daily_to_weekly(daily_series, agg='last'):
    """
    å°‡æ—¥ç·š Series è½‰ç‚ºå‘¨ç·šï¼Œä½¿ç”¨ ISO å‘¨æ¬¡åˆ†çµ„
    
    é‚è¼¯ï¼š
    - ç”¨ isocalendar() å–å¾—æ¯å€‹äº¤æ˜“æ—¥çš„ (year, week)
    - åŒä¸€ (year, week) çš„äº¤æ˜“æ—¥æ­¸ç‚ºåŒä¸€é€±
    - æ­£ç¢ºè™•ç†å‡æ—¥ï¼ˆå¦‚æ˜¥ç¯€é€±åªæœ‰ 2~3 å¤©äº¤æ˜“ï¼‰
    
    Args:
        daily_series: æ—¥ç·šè³‡æ–™ pd.Series (DatetimeIndex)
        agg: èšåˆæ–¹å¼ 'last'(æ”¶ç›¤), 'max'(æœ€é«˜), 'min'(æœ€ä½),
             'first'(é–‹ç›¤), 'sum'(æˆäº¤é‡)
    
    Returns:
        pd.Series: å‘¨ç·šè³‡æ–™ï¼Œindex ç‚ºè©²é€±æœ€å¾Œä¸€å€‹äº¤æ˜“æ—¥
    """
    if daily_series.empty:
        return daily_series
    
    # å»ºç«‹ (year, week) åˆ†çµ„ key
    iso = daily_series.index.isocalendar()
    group_key = iso.year.astype(str) + '-W' + iso.week.astype(str).str.zfill(2)
    
    grouped = daily_series.groupby(group_key)
    
    if agg == 'last':
        result = grouped.last()
    elif agg == 'max':
        result = grouped.max()
    elif agg == 'min':
        result = grouped.min()
    elif agg == 'first':
        result = grouped.first()
    elif agg == 'sum':
        result = grouped.sum()
    else:
        result = grouped.last()
    
    # ç”¨æ¯çµ„æœ€å¾Œä¸€å€‹äº¤æ˜“æ—¥ä½œç‚º indexï¼ˆä¿ç•™ DatetimeIndexï¼‰
    last_dates = daily_series.groupby(group_key).apply(lambda x: x.index[-1])
    result.index = last_dates.values
    result.index = pd.DatetimeIndex(result.index)
    result = result.sort_index()
    
    return result


# ============================================================
# ğŸ“ˆ æ—¥ç·šèƒŒé›¢æƒæ
# ============================================================

def scan_daily_divergences(candidates, df_close, df_high, df_low,
                           name_map, s_close, s_pchg):
    """
    æ—¥ç·š RSI èƒŒé›¢æƒæï¼ˆç¨ç«‹å‡½æ•¸ï¼‰
    
    Args:
        candidates: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        df_close/df_high/df_low: æ—¥ç·š OHLC DataFrame
        name_map: è‚¡ç¥¨åç¨±å°ç…§è¡¨
        s_close: æœ€æ–°æ”¶ç›¤åƒ¹ Series
        s_pchg: æœ€æ–°æ¼²è·Œå¹… Series
    
    Returns:
        list of dict: æ—¥ç·šèƒŒé›¢è¨Šè™Ÿåˆ—è¡¨
    """
    print(f"\nğŸ“ˆ æ—¥ç·š RSI èƒŒé›¢æƒæ (RSI={RSI_PERIOD}, Pivot L={PIVOT_LB_LEFT}/R={PIVOT_LB_RIGHT})...")
    
    daily_results = []
    total = len(candidates)
    
    for i, code in enumerate(candidates):
        if (i + 1) % 50 == 0:
            print(f"   Progress: {i + 1}/{total}...", end="\r")
        
        try:
            price_close = df_close[code].dropna()
            price_high = df_high[code].dropna()
            price_low = df_low[code].dropna()
            
            common_idx = price_close.index.intersection(price_high.index).intersection(price_low.index)
            if len(common_idx) < 100:
                continue
            
            pc = price_close.loc[common_idx]
            ph = price_high.loc[common_idx]
            pl = price_low.loc[common_idx]
            
            signals = check_divergences_for_stock(
                pc, ph, pl,
                rsi_period=RSI_PERIOD,
                max_bars_ago=0  # åªå–ä»Šå¤©ç¢ºèªçš„
            )
            
            for sig in signals:
                daily_results.append({
                    "code": code,
                    "name": name_map.get(code, code),
                    "price": s_close[code],
                    "pchg": s_pchg.get(code, 0.0),
                    "signal": sig,
                    "timeframe": "æ—¥ç·š"
                })
        except Exception as e:
            if DEBUG_MODE:
                print(f"   âš ï¸ {code} è™•ç†å¤±æ•—: {str(e)[:50]}")
            continue
    
    print(f"\nâœ… æ—¥ç·šæƒæå®Œæˆï¼ç™¼ç¾ {len(daily_results)} å€‹èƒŒé›¢è¨Šè™Ÿã€‚")
    return daily_results


# ============================================================
# ğŸ“Š å‘¨ç·šèƒŒé›¢æƒæ
# ============================================================

def scan_weekly_divergences(candidates, df_close, df_high, df_low,
                            name_map, s_close, s_pchg):
    """
    å‘¨ç·š RSI èƒŒé›¢æƒæï¼ˆç¨ç«‹å‡½æ•¸ï¼‰
    
    ä½¿ç”¨ ISO å‘¨æ¬¡åˆ†çµ„å»ºæ§‹å‘¨ç·šè³‡æ–™ï¼ˆé resample('W-FRI')ï¼‰ã€‚
    æ¯é€±çš„äº¤æ˜“æ—¥æ ¹æ“šå¯¦éš›æ—¥æ›†å‘¨æ¬¡æ­¸é¡ï¼Œç¢ºä¿å‡æ—¥é€±æ­£ç¢ºè™•ç†ã€‚
    
    Args:
        candidates: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨
        df_close/df_high/df_low: æ—¥ç·š OHLC DataFrame
        name_map: è‚¡ç¥¨åç¨±å°ç…§è¡¨
        s_close: æœ€æ–°æ”¶ç›¤åƒ¹ Series
        s_pchg: æœ€æ–°æ¼²è·Œå¹… Series
    
    Returns:
        list of dict: å‘¨ç·šèƒŒé›¢è¨Šè™Ÿåˆ—è¡¨
    """
    print(f"\nğŸ“Š å‘¨ç·š RSI èƒŒé›¢æƒæ (ISO å‘¨æ¬¡åˆ†çµ„)...")
    
    weekly_results = []
    total = len(candidates)
    
    for i, code in enumerate(candidates):
        if (i + 1) % 50 == 0:
            print(f"   Weekly Progress: {i + 1}/{total}...", end="\r")
        
        try:
            price_close = df_close[code].dropna()
            price_high = df_high[code].dropna()
            price_low = df_low[code].dropna()
            
            common_idx = price_close.index.intersection(price_high.index).intersection(price_low.index)
            if len(common_idx) < 100:
                continue
            
            pc = price_close.loc[common_idx]
            ph = price_high.loc[common_idx]
            pl = price_low.loc[common_idx]
            
            # ç”¨ ISO å‘¨æ¬¡åˆ†çµ„è½‰å‘¨ç·š
            weekly_close = daily_to_weekly(pc, agg='last')
            weekly_high = daily_to_weekly(ph, agg='max')
            weekly_low = daily_to_weekly(pl, agg='min')
            
            if len(weekly_close) < 30:
                continue
            
            signals = check_divergences_for_stock(
                weekly_close, weekly_high, weekly_low,
                rsi_period=RSI_PERIOD,
                max_bars_ago=0  # åªå–æœ¬é€±ç¢ºèªçš„
            )
            
            for sig in signals:
                weekly_results.append({
                    "code": code,
                    "name": name_map.get(code, code),
                    "price": s_close[code],
                    "pchg": s_pchg.get(code, 0.0),
                    "signal": sig,
                    "timeframe": "å‘¨ç·š"
                })
        except Exception as e:
            if DEBUG_MODE:
                print(f"   âš ï¸ {code} å‘¨ç·šè™•ç†å¤±æ•—: {str(e)[:50]}")
            continue
    
    print(f"\nâœ… å‘¨ç·šæƒæå®Œæˆï¼ç™¼ç¾ {len(weekly_results)} å€‹èƒŒé›¢è¨Šè™Ÿã€‚")
    return weekly_results


# ============================================================
# ğŸš€ ä¸»ç¯©é¸æµç¨‹
# ============================================================

def run_screener():
    """ä¸»ç¯©é¸æµç¨‹"""
    print("ğŸš€ å•Ÿå‹• RSI èƒŒé›¢ç¯©é¸ç³»çµ± v3.1 (TradingView Pivot + ISO å‘¨ç·š)...")
    print(f"   ğŸ“‹ RSI={RSI_PERIOD} | Pivot L={PIVOT_LB_LEFT} R={PIVOT_LB_RIGHT} | Range={RANGE_LOWER}~{RANGE_UPPER}")
    
    # æª¢æŸ¥äº¤æ˜“æ—¥
    if not is_trading_day():
        return
    
    # è¼‰å…¥è³‡æ–™
    data = load_data()
    if data is None:
        return
    
    df_close = data.get('close')
    df_high = data.get('high')
    df_low = data.get('low')
    df_volume = data.get('volume')
    
    if df_close is None or df_high is None or df_low is None:
        print("âŒ ç¼ºå°‘å¿…è¦è³‡æ–™ (close/high/low).")
        return
    
    # å‰å‘å¡«å……ç¼ºå¤±å€¼
    df_close = df_close.ffill()
    df_high = df_high.ffill()
    df_low = df_low.ffill()
    
    idx = -1
    date_str = df_close.index[idx].strftime('%Y-%m-%d')
    print(f"ğŸ“… åˆ†ææ—¥æœŸ: {date_str}")
    
    s_close = df_close.iloc[idx]
    
    # ========================================
    # ç¬¬ä¸€éšæ®µï¼šåŸºç¤éæ¿¾ (Filter 1, 2, 3)
    # ========================================
    print("\nğŸŒŠ ç¬¬ä¸€éšæ®µï¼šåŸºç¤éæ¿¾ (Filters 1,2,3)...")
    
    # Filter 1: æµå‹•æ€§ (20æ—¥å‡é‡æˆäº¤é¡ > 5000è¬)
    if 'vol_ma20' in data:
        s_vol_ma20 = data['vol_ma20'].iloc[idx]
    else:
        s_vol_ma20 = df_volume.rolling(20).mean().iloc[idx]
    s_turnover = s_close * s_vol_ma20
    mask_liquid = (s_turnover > LIQUIDITY_THRESHOLD)
    
    # Filter 2: è¶¨å‹¢æ’åˆ— (Close > MA50 > MA150 > MA200)
    ma50 = df_close.rolling(50).mean()
    ma150 = df_close.rolling(150).mean()
    ma200 = df_close.rolling(200).mean()
    
    s_ma50 = ma50.iloc[idx]
    s_ma150 = ma150.iloc[idx]
    s_ma200 = ma200.iloc[idx]
    
    mask_trend_order = (s_close > s_ma50) & (s_ma50 > s_ma150) & (s_ma150 > s_ma200)
    
    # Filter 3: è¶¨å‹¢å‘ä¸Š (MA200 10æ—¥æ–œç‡ > 0)
    def calc_ma_slope(ma_series, window=10):
        def linear_slope(y):
            if len(y) < window or y.isna().any():
                return np.nan
            x = np.arange(len(y))
            return np.polyfit(x, y, 1)[0]
        return ma_series.rolling(window).apply(linear_slope, raw=False)
    
    ma200_slope = calc_ma_slope(ma200, window=10)
    s_ma200_slope = ma200_slope.iloc[idx]
    mask_trend_up = s_ma200_slope > 0
    
    # åˆä½µéæ¿¾æ¢ä»¶
    mask_final = mask_liquid & mask_trend_order & mask_trend_up
    candidates = s_close[mask_final].index.tolist()
    
    print(f"   ğŸ” åˆé¸åˆæ ¼: {len(candidates)} æª”")
    
    # è¼‰å…¥åç¨±å°ç…§
    name_map = load_name_map()
    
    # è¨ˆç®—æ¼²è·Œå¹…
    s_prev = df_close.iloc[idx - 1]
    s_pchg = (s_close - s_prev) / s_prev * 100
    
    # ========================================
    # ç¬¬äºŒéšæ®µï¼šæ—¥ç·š RSI èƒŒé›¢æƒæ
    # ========================================
    daily_candidates = scan_daily_divergences(
        candidates, df_close, df_high, df_low,
        name_map, s_close, s_pchg
    )
    
    # ========================================
    # ç¬¬ä¸‰éšæ®µï¼šå‘¨ç·š RSI èƒŒé›¢æƒæ
    # ========================================
    weekly_candidates = []
    if ENABLE_WEEKLY:
        weekly_candidates = scan_weekly_divergences(
            candidates, df_close, df_high, df_low,
            name_map, s_close, s_pchg
        )
    
    # ========================================
    # è¼¸å‡ºå ±å‘Š
    # ========================================
    all_candidates = daily_candidates + weekly_candidates
    
    TYPE_LABELS = {
        'bull': ('ğŸ’', 'Regular Bullish', 'åº•èƒŒé›¢'),
        'hidden_bull': ('ğŸ”¹', 'Hidden Bullish', 'éš±è—åº•èƒŒé›¢'),
        'bear': ('ğŸ”´', 'Regular Bearish', 'é ‚èƒŒé›¢'),
        'hidden_bear': ('ğŸ”¸', 'Hidden Bearish', 'éš±è—é ‚èƒŒé›¢'),
    }
    
    if all_candidates:
        msg = f"ğŸ“Š **RSI èƒŒé›¢ç¯©é¸** (TradingView Pivot)\nğŸ“… {date_str}\n\n"
        
        for tf_label, tf_list in [("ğŸ“ˆ ã€æ—¥ç·šã€‘", daily_candidates), ("ğŸ“Š ã€å‘¨ç·šã€‘", weekly_candidates)]:
            if not tf_list:
                continue
            
            msg += f"{tf_label}\n"
            
            by_type = {}
            for x in tf_list:
                t = x['signal']['type']
                by_type.setdefault(t, []).append(x)
            
            for div_type in ['bull', 'hidden_bull', 'bear', 'hidden_bear']:
                items = by_type.get(div_type, [])
                if not items:
                    continue
                
                emoji, eng_label, cn_label = TYPE_LABELS[div_type]
                msg += f"\n{emoji} {cn_label} ({eng_label}) Ã— {len(items)}\n"
                
                for x in items:
                    sig = x['signal']
                    sign = "+" if x['pchg'] >= 0 else ""
                    msg += f"  {emoji} {x['code']} {x['name']}"
                    msg += f" | {x['price']:.1f}({sign}{x['pchg']:.1f}%)"
                    msg += f" | RSI: {sig['rsi_prev']:.0f}â†’{sig['rsi_curr']:.0f}"
                    msg += f" | Price: {sig['price_prev']:.1f}â†’{sig['price_curr']:.1f}\n"
            
            msg += "\n"
        
        send_tg_msg(msg)
        print("\nğŸ“¢ å ±å‘Šå·²ç™¼é€è‡³ Telegramã€‚")
        
        # å­˜æª”åˆ° CSV
        df_result = pd.DataFrame([
            {
                'code': x['code'],
                'name': x['name'],
                'timeframe': x['timeframe'],
                'div_type': x['signal']['type'],
                'price': x['price'],
                'pchg': x['pchg'],
                'rsi_curr': x['signal']['rsi_curr'],
                'rsi_prev': x['signal']['rsi_prev'],
                'price_curr': x['signal']['price_curr'],
                'price_prev': x['signal']['price_prev'],
                'date_pivot': x['signal']['date_pivot'].strftime('%Y-%m-%d'),
                'date_confirm': x['signal']['date_confirm'].strftime('%Y-%m-%d'),
                'bars_ago': x['signal']['bars_ago'],
            }
            for x in all_candidates
        ])
        
        csv_filename = os.path.join(project_root, 'logs', f'rsi_divergence_{date_str}.csv')
        os.makedirs(os.path.dirname(csv_filename), exist_ok=True)
        df_result.to_csv(csv_filename, index=False, encoding='utf-8-sig')
        print(f"âœ… çµæœå·²å­˜æª”è‡³ {csv_filename}")
    else:
        print("\nğŸ‚ ä»Šæ—¥ç„¡ç¬¦åˆ RSI èƒŒé›¢çš„è‚¡ç¥¨ã€‚")
        send_tg_msg(f"ğŸ“Š **RSI èƒŒé›¢ç¯©é¸**\nğŸ“… {date_str}\n\nä»Šæ—¥ç„¡ç¬¦åˆæ¨™æº–çš„æ¨™çš„ã€‚")


def send_tg_msg(message):
    """ç™¼é€ Telegram è¨Šæ¯"""
    CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "")
    TOKEN = os.getenv("TELEGRAM_TOKEN", "")
    if not TOKEN or not CHAT_ID:
        return
    try:
        requests.post(
            f"https://api.telegram.org/bot{TOKEN}/sendMessage",
            json={"chat_id": CHAT_ID, "text": message, "parse_mode": "Markdown"},
            timeout=10
        )
    except Exception:
        pass


if __name__ == "__main__":
    try:
        run_screener()
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
